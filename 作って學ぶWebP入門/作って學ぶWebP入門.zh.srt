1
00:00:00,000 --> 00:00:04,000
邊做邊學 WebP 入門

2
00:00:04,000 --> 00:00:06,379
用 Swift 做你自己的 WebP codec

3
00:00:06,379 --> 00:00:08,380
大家好 我是岸川克己

4
00:00:08,380 --> 00:00:12,739
今天要和大家一起學習
一種叫 WebP 的影像格式是怎麼運作的

5
00:00:12,739 --> 00:00:17,500
不只限於軟體
要理解任何東西的原理或機制

6
00:00:17,500 --> 00:00:19,338
最快的捷徑 就是親手做做看

7
00:00:19,338 --> 00:00:24,859
所以這次
我們會動手實作 WebP 的編解碼器

8
00:00:24,859 --> 00:00:27,658
來理解它的資料結構與壓縮原理

9
00:00:27,658 --> 00:00:32,719
所謂編解碼器 (codec)
就是把 編碼器 (encoder) 和
解碼器 (decoder) 合在一起的稱呼

10
00:00:32,719 --> 00:00:35,978
是 "encoder" 和
"decoder" 兩個字的組合

11
00:00:35,978 --> 00:00:39,340
雖說是邊做邊學

12
00:00:39,340 --> 00:00:42,380
但對大多數人來說 實作 WebP 很難

13
00:00:42,380 --> 00:00:45,200
常常會搞不清楚自己到底在做什麼

14
00:00:45,200 --> 00:00:51,118
因此這場演講的目的
就是幫你排除這些學習障礙

15
00:00:51,118 --> 00:00:56,238
WebP 的實作之所以難
其中一個原因是

16
00:00:56,238 --> 00:01:03,319
首先規格書預設
你已經懂了影像格式和壓縮技術

17
00:01:03,319 --> 00:01:09,040
所以沒有那些知識儲備的話
光看規格書 根本看不懂在幹嘛

18
00:01:09,040 --> 00:01:13,920
你可能會想
實作協定不就是照著規格書寫嗎

19
00:01:13,920 --> 00:01:18,858
一開始我也這麼想
然而 並不是

20
00:01:18,858 --> 00:01:21,459
於是想說 那不然來讀程式碼吧

21
00:01:21,459 --> 00:01:24,060
以為讀了就會懂

22
00:01:24,060 --> 00:01:30,180
結果能參考的 WebP 實作
基本上只有那個用 C 語言寫的官方實作

23
00:01:30,180 --> 00:01:35,218
而那份實作裡面
有最佳化並行處理之類的其他功能分支

24
00:01:35,218 --> 00:01:38,819
導致很多核心功能外的地方
規模變得很大 相當複雜

25
00:01:38,819 --> 00:01:41,900
拿來學習其實不太適合

26
00:01:41,900 --> 00:01:48,218
再說 壓縮演算法和
一般的程式設計 思路差很多

27
00:01:48,218 --> 00:01:51,819
在還沒理解原理的階段去讀 是很困難的

28
00:01:51,819 --> 00:01:54,159
所以不管你看規格或看程式碼

29
00:01:54,159 --> 00:01:57,739
都很難了解它到底在做什麼

30
00:01:57,739 --> 00:01:59,239
這就是第一道門檻

31
00:01:59,239 --> 00:02:02,900
就算好不容易跨過這道障礙

32
00:02:02,900 --> 00:02:07,459
把規格讀懂 準備開始實作

33
00:02:07,459 --> 00:02:11,919
即便如此 沒有非常強的動力的話

34
00:02:11,919 --> 00:02:14,680
大概很快就會半途而廢

35
00:02:14,680 --> 00:02:19,860
因為 WebP 的機制是由許多小步驟堆疊起來

36
00:02:19,860 --> 00:02:22,280
最後讓檔案變小的一套流程

37
00:02:22,280 --> 00:02:23,378
它大致上就是這樣的機制

38
00:02:23,378 --> 00:02:28,240
而壓縮或解碼這類處理 是非黑即白的

39
00:02:28,240 --> 00:02:30,960
就算你實作得沒錯

40
00:02:30,960 --> 00:02:34,699
在半成品階段 也完全不會顯示出可視結果

41
00:02:34,699 --> 00:02:41,340
所以想確認結果
就得把整個流程先全部做完

42
00:02:41,340 --> 00:02:44,580
但各個步驟環節彼此相依

43
00:02:44,580 --> 00:02:46,938
因為各階段都和後續階段互相依賴

44
00:02:46,938 --> 00:02:50,900
很難把它們分離 進行獨立驗證

45
00:02:50,900 --> 00:02:58,580
換句話說
就像在一片前路迷茫的森林裡 走一段很長的路

46
00:02:58,580 --> 00:03:01,199
寫著寫著 也不知道自己到底對不對

47
00:03:01,199 --> 00:03:03,580
老是在懷疑「這有對嗎？」

48
00:03:03,580 --> 00:03:06,598
一路寫到最後 才「砰」的一聲驗證

49
00:03:06,598 --> 00:03:10,080
然後發現「不行 錯了」 常會變成這樣

50
00:03:10,080 --> 00:03:13,419
能一直撐下去的人其實不多

51
00:03:13,419 --> 00:03:19,740
所以在這場演講中
我們先把壓縮率等細節都先放一邊

52
00:03:19,740 --> 00:03:25,258
先做出一張
只要能成功識別為 WebP 圖片 就算完成的

53
00:03:25,258 --> 00:03:28,500
極度精簡的最小實作原型

54
00:03:28,500 --> 00:03:34,139
接著再準備好一個能把它解碼的解碼器

55
00:03:34,139 --> 00:03:36,900
以此為基礎 一個一個累加功能

56
00:03:36,900 --> 00:03:41,020
每加一個 這邊能顯示圖片 那邊也能解碼

57
00:03:41,020 --> 00:03:44,979
再加一個 同樣地反覆確認

58
00:03:44,979 --> 00:03:49,818
如此就能逐步地進行局部確認

59
00:03:49,818 --> 00:03:54,840
每步實作是否有正確建立起來
這樣一步一步的驗證流程來推進

60
00:03:54,840 --> 00:03:59,158
這樣最終就能做出一個完整功能的
WebP 編解碼器

61
00:03:59,158 --> 00:04:03,020
為了做到這件事 我準備了一些東西

62
00:04:03,020 --> 00:04:05,218
而這場演講最重要的

63
00:04:05,218 --> 00:04:09,099
就是我為此準備的範例程式碼

64
00:04:09,099 --> 00:04:13,899
也就是那個最小實作的範例程式碼

65
00:04:13,899 --> 00:04:15,699
以及測試資料

66
00:04:15,699 --> 00:04:18,100
我覺得這大概是最重要的

67
00:04:18,100 --> 00:04:19,980
比我現在講的內容還重要

68
00:04:19,980 --> 00:04:22,180
用 Swift 寫的 WebP 編解碼器

69
00:04:22,180 --> 00:04:24,180
市面上根本不存在

70
00:04:24,180 --> 00:04:25,240
目前就只有我做的這個

71
00:04:25,240 --> 00:04:29,860
而且還特地為學習用途
盡量不使用多餘的技巧

72
00:04:29,860 --> 00:04:32,420
這種寫法真的就只有我這個

73
00:04:32,420 --> 00:04:37,040
所以我覺得這次做出來的東西還不錯

74
00:04:37,040 --> 00:04:41,120
範例程式碼已經在這個 GitHub repo 上公開

75
00:04:41,120 --> 00:04:42,079
應該看得到

76
00:04:42,079 --> 00:04:47,300
這次的內容大致如下

77
00:04:47,300 --> 00:04:49,240
首先先來講 WebP

78
00:04:49,240 --> 00:04:51,199
可能有些人不太熟

79
00:04:51,199 --> 00:04:52,420
我會先快速複習一下

80
00:04:52,420 --> 00:04:57,980
然後也會提一下在 iOS 上能不能用
WebP 之類的話題

81
00:04:57,980 --> 00:05:00,500
接著談談資料結構

82
00:05:00,500 --> 00:05:03,819
一邊介紹 一邊實際讀讀看檔案

83
00:05:03,819 --> 00:05:06,920
還有最小實作

84
00:05:06,920 --> 00:05:09,480
以及產生壓縮資料

85
00:05:09,480 --> 00:05:12,838
還有在學 WebP 時會用到的
高效資料壓縮技術

86
00:05:12,838 --> 00:05:14,139
我也會一路穿插著說明

87
00:05:14,139 --> 00:05:18,579
最後做個總結與下一步建議 來回顧學到什麼

88
00:05:18,579 --> 00:05:20,759
以及接下來做些什麼會比較有趣

89
00:05:20,759 --> 00:05:21,800
也都會聊到

90
00:05:21,800 --> 00:05:25,319
那就先來複習一下 WebP

91
00:05:25,319 --> 00:05:26,800
WebP 是什麼

92
00:05:26,800 --> 00:05:29,600
WebP 是一種在網站或 App 上

93
00:05:29,600 --> 00:05:31,959
很適合用來顯示的影像格式

94
00:05:31,959 --> 00:05:34,740
這裡說的「適合」是什麼意思呢

95
00:05:34,740 --> 00:05:36,399
追根究柢 這個格式開發的動機就是

96
00:05:36,399 --> 00:05:39,680
比起其他格式 更盡可能地
把資料容量壓到最小

97
00:05:39,680 --> 00:05:41,639
它一開始就是以此為目的來開發的

98
00:05:41,639 --> 00:05:43,579
也就是說 預設情境就是為了網路傳輸所設想的

99
00:05:43,579 --> 00:05:46,240
考慮到進行傳送與接收的情境 來設想的

100
00:05:46,240 --> 00:05:52,120
從一開始就支援 Alpha 通道標準
也就是背景透明之類的

101
00:05:52,120 --> 00:05:54,079
另外也支援動畫

102
00:05:54,079 --> 00:05:58,759
所以像圖示 UI 元素等 都很好用

103
00:05:58,759 --> 00:06:00,920
也就是說 它是一個好上手的格式

104
00:06:00,920 --> 00:06:02,620
到這裡為止

105
00:06:02,620 --> 00:06:05,120
我想很多人應該都知道

106
00:06:05,120 --> 00:06:07,920
但其實有個 WebP
不太被注意到的特性是

107
00:06:07,920 --> 00:06:11,620
破壞性壓縮(有損壓縮) 和無損壓縮
兩者都支援

108
00:06:11,620 --> 00:06:12,420
有這樣的特性

109
00:06:12,420 --> 00:06:14,939
以行動 App 的使用情境來說

110
00:06:14,939 --> 00:06:17,540
大多會把它當作 PNG 的替代品來用

111
00:06:17,540 --> 00:06:19,120
我想這種用法很常見

112
00:06:19,120 --> 00:06:22,939
所以很多人的認知是
WebP 用無損壓縮會比 PNG 還小

113
00:06:22,939 --> 00:06:26,639
應該不少人是這樣理解的

114
00:06:26,639 --> 00:06:31,480
但實際上
WebP 也能用像 JPEG 那樣的有損壓縮

115
00:06:31,480 --> 00:06:38,360
而且實務上 有損格式反而用得更多

116
00:06:38,360 --> 00:06:42,160
在大多數與 WebP 相關的工具裡

117
00:06:42,160 --> 00:06:48,800
因為資料量更小 預設多半都是有損壓縮形式

118
00:06:48,800 --> 00:06:53,639
所以 如果你以為用 WebP
就不會有品質劣化

119
00:06:53,639 --> 00:06:58,338
但用工具把 PNG 轉 WebP 時
可能預設就用有損壓縮了

120
00:06:58,338 --> 00:07:00,040
這裡要特別小心別踩坑

121
00:07:00,040 --> 00:07:05,420
總結一下 WebP 是為了網頁或
App 的傳輸效率

122
00:07:05,420 --> 00:07:09,180
以盡量降低資料大小為目的所打造

123
00:07:09,180 --> 00:07:12,680
有損壓縮可以用在照片

124
00:07:12,680 --> 00:07:15,100
無損壓縮的話 就很適合插畫或圖示

125
00:07:15,100 --> 00:07:19,879
基本上能涵蓋幾乎所有類型的影像

126
00:07:19,879 --> 00:07:23,139
也就是同時支援有損和無損兩種壓縮模式

127
00:07:23,139 --> 00:07:26,899
大概知道到這個程度就差不多了

128
00:07:26,899 --> 00:07:31,180
接著談談在 iOS 上的支援狀況

129
00:07:31,180 --> 00:07:34,540
基本上 iOS 14 之後就幾乎都能用了

130
00:07:34,540 --> 00:07:37,879
應該說幾乎是完整可用

131
00:07:37,879 --> 00:07:40,778
在 Safari、WebView
顯示網頁沒問題

132
00:07:40,778 --> 00:07:43,319
如果是在原生 App 端操作

133
00:07:43,319 --> 00:07:45,338
用 CGImageSource 的話

134
00:07:45,338 --> 00:07:48,579
不論是單張靜態圖或動畫都能讀取

135
00:07:48,579 --> 00:07:51,180
如果只需要靜態圖

136
00:07:51,180 --> 00:07:54,740
也可以用 UIImage 的
initializer 直接實體化

137
00:07:54,740 --> 00:07:57,540
不過編碼 (encode) 這塊不支援

138
00:07:57,540 --> 00:07:59,220
可以輸出 PNG 格式

139
00:07:59,220 --> 00:08:03,278
但在 iOS 或 Mac 上
並不支援直接輸出 WebP 檔案

140
00:08:03,278 --> 00:08:05,439
所以接下來

141
00:08:05,439 --> 00:08:08,740
我想帶大家看看 WebP 的內部

142
00:08:08,740 --> 00:08:12,420
先照慣例從資料結構開始看起

143
00:08:12,420 --> 00:08:16,079
和一般的資料格式一樣

144
00:08:16,079 --> 00:08:18,399
WebP 也分成 header 和 data

145
00:08:18,399 --> 00:08:21,838
header 裡放的是資料種類 大小等
這些中繼資料

146
00:08:21,838 --> 00:08:24,538
而實際影像內容則在 data 部分

147
00:08:24,538 --> 00:08:28,220
在 WebP 裡
header 和 data

148
00:08:28,220 --> 00:08:30,879
並不是 WebP 自創的設計

149
00:08:30,879 --> 00:08:33,019
而是沿用其他檔案格式也會用到的

150
00:08:33,019 --> 00:08:36,960
RIFF 資源交換檔案格式
(Resource Interchange File Format)

151
00:08:36,960 --> 00:08:40,899
RIFF 是一種通用的資料格式

152
00:08:40,899 --> 00:08:45,620
設計上就像個簡單的容器 可以放任意資料

153
00:08:45,620 --> 00:08:52,298
所以 RIFF 最上層的結構
也會被稱作 RIFF container

154
00:08:52,298 --> 00:08:59,139
RIFF 的結構
是由稱為 Chunk （區塊）的資料群組組成

155
00:08:59,139 --> 00:09:03,139
一個 RIFF container
可以包含多個 Chunk

156
00:09:03,139 --> 00:09:10,658
Chunk 的結構中
開頭有個表示資料類型的識別 ID 稱為 FourCC
(Four-Character Code)

157
00:09:10,658 --> 00:09:14,340
FourCC 是由四個 ASCII 字元組成

158
00:09:14,340 --> 00:09:15,200
所以才會這樣稱呼

159
00:09:15,200 --> 00:09:16,879
就是四個字元這樣

160
00:09:16,879 --> 00:09:22,418
下個區塊是標記 Chunk 本體 (Payload)
的資料大小

161
00:09:22,418 --> 00:09:24,298
先看第一個 Chunk

162
00:09:24,298 --> 00:09:27,340
如果是 RIFF 檔 這裡會表示它是一個
RIFF container

163
00:09:27,340 --> 00:09:30,519
這裡一定會是 'R' 'I' 'F' 'F'

164
00:09:30,519 --> 00:09:32,340
也就是 "RIFF" 這個 ID

165
00:09:32,340 --> 00:09:34,360
不只 WebP

166
00:09:34,360 --> 00:09:37,259
任何採用這個
RIFF container 的檔案格式

167
00:09:37,259 --> 00:09:40,519
必定會以 RIFF 開頭

168
00:09:40,519 --> 00:09:43,440
然後是紀錄「實際資料區塊」部分的大小

169
00:09:43,440 --> 00:09:46,519
比方說 如果只有一個 Chunk

170
00:09:46,519 --> 00:09:48,960
總體大小是 100 bytes 的話

171
00:09:48,960 --> 00:09:55,100
這個 size 區塊 會扣掉開頭的 "RIFF" 區塊
與自己本身的容量（各 4 bytes）

172
00:09:55,100 --> 00:09:57,580
也就是會寫入 92 bytes

173
00:09:57,580 --> 00:10:01,360
以 WebP 檔來說

174
00:10:01,360 --> 00:10:03,360
這個 RIFF Chunk 的 payload

175
00:10:03,360 --> 00:10:06,500
區塊開頭會放表示 WebP 檔的 FourCC ID

176
00:10:06,500 --> 00:10:09,778
也就是寫上
'W' 'E' 'B' 'P' 這個名字

177
00:10:09,778 --> 00:10:11,399
直接作為識別 ID 放進去

178
00:10:11,399 --> 00:10:17,678
讀到這裡
你就知道這個檔是 WebP 格式了

179
00:10:17,678 --> 00:10:23,778
從開頭到 'W' 'E' 'B' 'P' 為止
這個 FourCC 區塊的 12 bytes

180
00:10:23,778 --> 00:10:25,960
有時也被稱為 "WebP header"

181
00:10:25,960 --> 00:10:33,240
接著 就要依照 WebP 格式規格 繼續解讀

182
00:10:33,240 --> 00:10:38,940
這樣一來
就能知道 WebP 還支援哪些功能

183
00:10:38,940 --> 00:10:41,960
包含影像形式與有哪些功能需要做控制

184
00:10:41,960 --> 00:10:47,820
如剛才提到的 WebP 標準就支援兩種格式
有損與無損

185
00:10:47,820 --> 00:10:51,259
所以可知 內部至少會有這兩種資料

186
00:10:51,259 --> 00:10:53,600
如果有用到動畫的話

187
00:10:53,600 --> 00:10:56,298
就會包含多個影像資料

188
00:10:56,298 --> 00:10:58,658
而在各個圖片的動畫影格中

189
00:10:58,658 --> 00:11:00,778
也支援同時混用有損和無損兩種形式

190
00:11:00,778 --> 00:11:06,558
還支援嵌入像是
Exif 或 ICC 色彩設定檔這類的中繼資料

191
00:11:06,558 --> 00:11:10,639
比方說 裡面是有損格式的靜態圖時

192
00:11:10,639 --> 00:11:14,940
接著該 Chunk header 內容
會是 'V' 'P' '8' 後面再接一個空白字元

193
00:11:14,940 --> 00:11:18,240
因為 FourCC 是規定用四個英文字元

194
00:11:18,240 --> 00:11:20,658
所以最後一定會有一個空白

195
00:11:20,658 --> 00:11:21,940
只有三個字元是不行的

196
00:11:21,940 --> 00:11:25,320
要是 'V' 'P' '8' ' ' 這樣
含空白才是正式的 FourCC

197
00:11:25,320 --> 00:11:30,418
無損格式的 FourCC 則是
'V' 'P' '8' 'L'

198
00:11:30,418 --> 00:11:35,460
下一個 描述 Payload 大小的 Chunk
就是用 'WEBP" 全區塊總長度 扣掉標頭組的大小

199
00:11:35,460 --> 00:11:38,158
以範例來說
就是 Payload 大小有 80 個位元組

200
00:11:38,158 --> 00:11:40,058
接著在後面的 Chunk Payload 裡

201
00:11:40,058 --> 00:11:42,240
就會放入壓縮後的影像資料本體

202
00:11:42,240 --> 00:11:44,899
這種只有一個這樣的 Chunk 的

203
00:11:44,899 --> 00:11:46,320
WebP 格式

204
00:11:46,320 --> 00:11:49,440
在 WebP 裡稱為
"Simple File Format"

205
00:11:49,440 --> 00:11:55,240
對於有損和無損
壓縮方式和各種處理都完全不同

206
00:11:55,240 --> 00:11:56,960
幾乎沒有共通部分

207
00:11:56,960 --> 00:11:58,158
所以不能用同一套處理

208
00:11:58,158 --> 00:12:01,278
在解碼器的實作裡
會先看 Chunk Header

209
00:12:01,278 --> 00:12:04,678
然後把處理完全分成兩路不同的實作

210
00:12:04,678 --> 00:12:09,678
WebP 難實作的另一個理由是

211
00:12:09,678 --> 00:12:11,298
如果要把全部功能都實作出來

212
00:12:11,298 --> 00:12:13,240
在有損和無損這兩邊

213
00:12:13,240 --> 00:12:14,340
已經是完全不同的了

214
00:12:14,340 --> 00:12:18,200
基本上就像在寫兩套不同的軟體

215
00:12:18,200 --> 00:12:21,740
這點就相當辛苦

216
00:12:21,740 --> 00:12:25,178
想包含 Exif 中繼資料

217
00:12:25,178 --> 00:12:26,298
或是要用動畫的話

218
00:12:26,298 --> 00:12:28,759
就塞不進 Simple File Format

219
00:12:28,759 --> 00:12:31,379
需要用 Extended File Format

220
00:12:31,379 --> 00:12:33,600
在 Extended File Format 裡

221
00:12:33,600 --> 00:12:39,440
會放置一個 FourCC 為 "VP8X"
長度固定 10 bytes 的 Chunk

222
00:12:39,440 --> 00:12:45,100
一看到它 就知道後面還會跟著中繼資料或
動畫相關的資料

223
00:12:45,100 --> 00:12:49,418
這個 "VP8X"
會標示出有哪些功能被啟用

224
00:12:49,418 --> 00:12:51,860
那些 flag 就塞在這 10 個位元組裡

225
00:12:51,860 --> 00:12:57,538
當某個 flag 為啟用時
通常就會有對應的資料以 Chunk 的形式出現

226
00:12:57,538 --> 00:13:02,440
像 Exif 這種不影響渲染的資料
放哪裡都可以

227
00:13:02,440 --> 00:13:05,500
但像 ICC 色彩設定檔、動畫、Alpha 通道這些

228
00:13:05,500 --> 00:13:10,120
基本上就要照順序放在前面

229
00:13:10,120 --> 00:13:13,960
有規定這類資料 必須出現在影像資料之前

230
00:13:13,960 --> 00:13:21,620
比方說 flag 沒有打開動畫功能
卻出現了動畫的 Chunk

231
00:13:21,620 --> 00:13:27,658
或是混進一些與識別 ID 用途
完全無關的 Chunk

232
00:13:27,658 --> 00:13:29,899
基本上都會被忽略

233
00:13:29,899 --> 00:13:32,918
會被當作不明區塊 (Unknown Chunk)

234
00:13:32,918 --> 00:13:35,200
原則上不會當成錯誤

235
00:13:35,200 --> 00:13:40,820
利用這點 也可以把任意資料塞進檔案裡

236
00:13:40,820 --> 00:13:42,500
理論上是可行的

237
00:13:42,500 --> 00:13:44,600
總之呢

238
00:13:44,600 --> 00:13:49,080
作為起步 先來看看標頭部分

239
00:13:49,080 --> 00:13:54,418
如同剛才看到的 影像以外的資料部分

240
00:13:54,418 --> 00:13:57,639
是採用 RIFF 格式的結構

241
00:13:57,639 --> 00:13:59,639
會有 4 Bytes 的 FourCC

242
00:13:59,639 --> 00:14:01,080
接著是 4 Bytes 的容量資料欄位

243
00:14:01,080 --> 00:14:03,740
然後才是 Chunk Data

244
00:14:03,740 --> 00:14:06,778
於是就依讀到的容量大小 跳過這段資料

245
00:14:06,778 --> 00:14:08,120
如果後面還有資料

246
00:14:08,120 --> 00:14:10,658
再以同樣方式讀 4 Bytes 的 FourCC

247
00:14:10,658 --> 00:14:12,200
按順序讀下去就可以了

248
00:14:12,200 --> 00:14:14,158
也就是說所謂「讀取標頭」就是

249
00:14:14,158 --> 00:14:17,139
把影像資料的部分跳過 只讀標頭的感覺

250
00:14:17,139 --> 00:14:20,178
如果只是讀這些的話 就都是原始位元資料

251
00:14:20,178 --> 00:14:23,080
不需要先作解壓縮處理 非常簡單

252
00:14:23,080 --> 00:14:27,058
不過光是這樣
就能知道 WebP 檔是有損還是無損

253
00:14:27,058 --> 00:14:28,200
有沒有包含動畫

254
00:14:28,200 --> 00:14:30,620
都能拿得到這些資訊

255
00:14:30,620 --> 00:14:33,538
RIFF 標頭讀取工具呢
(RIFF Header Reader)

256
00:14:33,538 --> 00:14:36,399
大概是長這樣子

257
00:14:36,399 --> 00:14:39,460
它就叫做 RIFF Header Reader

258
00:14:39,460 --> 00:14:40,960
有放在範例程式裡

259
00:14:40,960 --> 00:14:45,379
這個 如果平常不太寫二進位操作的話

260
00:14:45,379 --> 00:14:47,899
可以先用這個當作入門來玩玩看

261
00:14:47,899 --> 00:14:50,240
試著多讀幾種 WebP 檔看看

262
00:14:50,240 --> 00:14:52,500
就會有種「喔 原來如此」的感覺

263
00:14:52,500 --> 00:14:54,500
應該也會蠻有趣的

264
00:14:54,500 --> 00:14:59,678
接下來就要正式來看影像資料的內容了

265
00:14:59,678 --> 00:15:02,360
就像一開始說的

266
00:15:02,360 --> 00:15:07,778
WebP 的影像資料 在沒有其他資料輔助下
是沒辦法直接讀取的

267
00:15:07,778 --> 00:15:08,840
並沒有這麼單純

268
00:15:08,840 --> 00:15:11,538
它經過了多個階段的壓縮與轉換

269
00:15:11,538 --> 00:15:16,200
幾乎沒有能直接讀取的原始位元資料

270
00:15:16,200 --> 00:15:19,460
所以先從其中一種處理開始

271
00:15:19,460 --> 00:15:22,980
我自己實作了
只有經過轉換處理的 WebP 圖片

272
00:15:22,980 --> 00:15:26,418
為什麼要自己做呢

273
00:15:26,418 --> 00:15:28,139
一方面是為了幫助理解

274
00:15:28,139 --> 00:15:30,980
但實際上不會有這麼單純的 WebP 檔案

275
00:15:30,980 --> 00:15:34,120
在 libwebp 函式庫的測試資料裡

276
00:15:34,120 --> 00:15:36,980
為了確認處理過程

277
00:15:36,980 --> 00:15:41,620
也有類似只套了某種轉換的測試資料

278
00:15:41,620 --> 00:15:43,759
不過就算要把它解碼

279
00:15:43,759 --> 00:15:45,178
還是需要相當的實作能力

280
00:15:45,178 --> 00:15:47,418
但沒有這種非常單純的測試資料

281
00:15:47,418 --> 00:15:49,700
所以只好自己做

282
00:15:49,700 --> 00:15:52,558
要做成什麼樣的資料呢

283
00:15:52,558 --> 00:15:57,778
從規格來想的話 就是有損或無損

284
00:15:57,778 --> 00:15:59,639
另外如果是動畫的話

285
00:15:59,639 --> 00:16:02,220
會包含多個有損或無損的資料

286
00:16:02,220 --> 00:16:03,600
大概是這樣

287
00:16:03,600 --> 00:16:08,178
首先中繼資料的部分
和這次要講的壓縮、解碼無關

288
00:16:08,178 --> 00:16:10,000
就先不納入範圍

289
00:16:10,000 --> 00:16:15,100
動畫的話 每個影格
基本上跟靜態圖也是一樣的概念

290
00:16:15,100 --> 00:16:16,960
這次也先不談

291
00:16:16,960 --> 00:16:25,058
不過動畫還會把背景分拆出來
只寫入變動的部分之類的

292
00:16:25,058 --> 00:16:29,038
還有那種只紀錄差分資料的動畫特有機制

293
00:16:29,038 --> 00:16:33,558
所以想要完整支援動畫的話
還是需要額外的實作

294
00:16:33,558 --> 00:16:37,298
那麼 在範例程式碼裡

295
00:16:37,299 --> 00:16:43,700
有同時支援包含 Alpha 通道的有損、無損
兩種圖形格式的編碼、解碼處理

296
00:16:44,860 --> 00:16:46,980
無損格式一定都包含 Alpha 通道

297
00:16:46,980 --> 00:16:49,720
就算 Simple File Format 也支援

298
00:16:49,720 --> 00:16:52,340
而 Extended File Format
當然也能正確讀取 Alpha 通道資料

299
00:16:52,340 --> 00:16:57,558
接下來先著重講解無損格式

300
00:16:57,558 --> 00:17:01,919
相較於有損 無損格式的各種處理都比較單純

301
00:17:01,919 --> 00:17:03,278
應該也比較好懂

302
00:17:03,278 --> 00:17:08,200
在資料的轉換過程
也比較容易看懂輸入了什麼

303
00:17:08,200 --> 00:17:10,740
只要有這種最小化的資料

304
00:17:10,740 --> 00:17:13,838
其實就能一步步推進 不會太難

305
00:17:13,838 --> 00:17:19,000
那我們來看 VP8L 的資料結構

306
00:17:19,000 --> 00:17:23,838
一般來說 WebP 的資料部分稱為
位元流 (Bitstream)

307
00:17:23,838 --> 00:17:27,858
位元流的開頭是稱為
"VP8L" 的標頭

308
00:17:27,858 --> 00:17:32,140
這個是固定值

309
00:17:32,140 --> 00:17:35,558
接著是寬度、高度資料

310
00:17:35,558 --> 00:17:37,880
然後會有關於是否有 Alpha 通道
以及版本的欄位

311
00:17:37,880 --> 00:17:42,038
以 VP8L 的無損資料來說

312
00:17:42,038 --> 00:17:43,538
一定會有 Alpha 通道資料

313
00:17:43,538 --> 00:17:45,880
這個讀不讀都沒差

314
00:17:45,880 --> 00:17:50,558
所以基本上只需要寬、高這兩個資訊

315
00:17:50,558 --> 00:17:54,519
版本值現在也都是 0 

316
00:17:54,519 --> 00:17:55,880
可以直接跳過沒關係

317
00:17:55,880 --> 00:17:57,880
不過如果來了不同的值

318
00:17:57,880 --> 00:17:59,660
就代表資料不合法

319
00:17:59,660 --> 00:18:01,500
通常會當成錯誤

320
00:18:01,500 --> 00:18:04,960
「位元流」顧名思義

321
00:18:04,960 --> 00:18:07,240
這些資料必須以 bit 為單位來讀

322
00:18:07,240 --> 00:18:11,558
像寬高本來就會跨越 byte 邊界

323
00:18:11,558 --> 00:18:15,578
因為這個格式傾向連 1 bit 都要省

324
00:18:15,578 --> 00:18:19,538
所以會盡量以 bit 單位 緊湊地寫入

325
00:18:19,538 --> 00:18:25,078
而大多數程式語言並沒有
直接讀取指定位置 bit 資料的功能

326
00:18:25,078 --> 00:18:26,759
這部分得自己實作

327
00:18:26,759 --> 00:18:31,140
做法就是把以 byte 讀進來的資料

328
00:18:31,140 --> 00:18:33,818
用 bit shift 取出需要的位元

329
00:18:33,818 --> 00:18:36,759
不夠的話就再讀 1 個 byte

330
00:18:36,759 --> 00:18:41,038
Header 的資料是
可以直接讀的原始位元資料

331
00:18:41,038 --> 00:18:44,140
只要先做出這種讀取 bit 資料的處理

332
00:18:44,140 --> 00:18:45,358
就能把標頭那段讀出來

333
00:18:45,358 --> 00:18:47,640
這樣能知道什麼呢

334
00:18:47,640 --> 00:18:50,058
就是影像的寬、高尺寸

335
00:18:50,058 --> 00:18:56,259
寬、高這項資訊
在做影像處理時非常重要

336
00:18:56,259 --> 00:19:00,200
因為影像資料 我們肉眼看是個矩形

337
00:19:00,200 --> 00:19:05,440
可是以軟體來說
它其實是在記憶體裡 一段連續的一維陣列資料

338
00:19:05,440 --> 00:19:17,460
而影像壓縮的方法
常常會假設「鄰近像素顏色相近」

339
00:19:17,460 --> 00:19:18,700
在那種情況下

340
00:19:18,700 --> 00:19:23,259
在記憶體上相鄰的資料
實際顯示出來 卻可能是左右兩端的像素

341
00:19:23,259 --> 00:19:30,640
反過來說 記憶體上相隔很遠的資料
畫面上卻可能是上下相鄰的像素

342
00:19:30,640 --> 00:19:33,980
所以寬高非常重要

343
00:19:33,980 --> 00:19:37,558
大多數格式
都會在讀到實際像素之前就讓你知道

344
00:19:37,558 --> 00:19:39,460
因此通常會放在檔頭前段

345
00:19:39,460 --> 00:19:41,598
也有少數放比較後面的格式啦

346
00:19:41,598 --> 00:19:46,140
標頭後面就是壓縮過的影像資料

347
00:19:46,140 --> 00:19:48,578
那就不是單純的原始位元資料了

348
00:19:48,578 --> 00:19:50,420
不做點處理是讀不出來的

349
00:19:50,420 --> 00:19:53,858
以無損資料的壓縮流程來說

350
00:19:53,858 --> 00:19:55,019
大概是像這樣

351
00:19:55,019 --> 00:19:58,680
大概會經過 3 到 6 種步驟 可能更多

352
00:19:58,680 --> 00:20:01,118
一路處理完才會成為可用資料

353
00:20:01,118 --> 00:20:04,038
這就是門檻所在

354
00:20:04,038 --> 00:20:05,798
關於各步驟的概念

355
00:20:05,798 --> 00:20:07,980
在規格書裡幾乎沒寫

356
00:20:07,980 --> 00:20:09,318
即使把步驟寫出來了

357
00:20:09,318 --> 00:20:10,538
也沒說這到底是什麼

358
00:20:10,538 --> 00:20:15,038
不懂這些流程的話 基本上就不知道這在做什麼

359
00:20:15,038 --> 00:20:18,058
還原 則是把它反過來做

360
00:20:18,058 --> 00:20:21,240
不管怎樣 只要不懂的話
兩種都寫不出來

361
00:20:21,240 --> 00:20:24,460
所以就需要對流程有一定的認識

362
00:20:24,460 --> 00:20:31,920
終究還是得把它一個一個搞懂

363
00:20:31,920 --> 00:20:34,420
但照一般方式做 其實很難

364
00:20:34,420 --> 00:20:38,980
在這裡先準備一個
只實作其中一步的編解碼器 (codec)

365
00:20:38,980 --> 00:20:40,519
以及對應的資料

366
00:20:40,519 --> 00:20:43,500
這樣就能先做第一步的驗證

367
00:20:43,500 --> 00:20:47,338
之後就可以持續往下接著做
採用這種漸進式做法

368
00:20:47,338 --> 00:20:50,720
這個我有當作範例程式公開

369
00:20:50,720 --> 00:20:52,338
就是剛剛提到的那個套件

370
00:20:52,338 --> 00:20:54,420
裡面每一個 對應到哪個步驟

371
00:20:54,420 --> 00:20:59,920
基本上有命名的那些
都對應到同名的壓縮流程

372
00:20:59,920 --> 00:21:04,640
這個 Bitstream 最後會

373
00:21:04,640 --> 00:21:08,900
被所謂的前綴編碼 (prefix coding) 
這種壓縮手法改寫

374
00:21:08,900 --> 00:21:12,180
所以前綴編碼這一步 是都一定會經過的

375
00:21:12,180 --> 00:21:18,058
除此之外 基本上每個套件都只做一件事

376
00:21:18,058 --> 00:21:20,098
也就是各自只實作其中一項

377
00:21:20,098 --> 00:21:26,298
第 8 個那個
則是完整功能的解碼器／編碼器

378
00:21:26,298 --> 00:21:29,700
總之 照我們剛才看到的

379
00:21:29,700 --> 00:21:32,940
必要的步驟其實就是前綴編碼

380
00:21:32,940 --> 00:21:35,598
所以先從實作前綴編碼開始

381
00:21:35,598 --> 00:21:40,759
雖然不存在只做了前綴編碼
就拿來當 WebP 圖片的東西

382
00:21:40,759 --> 00:21:45,220
但一開始把這個做出來
才是最根本的基礎

383
00:21:45,220 --> 00:21:48,180
與其說是前綴編碼

384
00:21:48,180 --> 00:21:49,420
大概大家更熟的是
霍夫曼編碼 (Huffman coding)

385
00:21:49,420 --> 00:21:52,338
或是霍夫曼解碼這種講法 會比較耳熟

386
00:21:52,338 --> 00:21:58,259
不過在 WebP 的規格書裡
霍夫曼解碼這個詞完全沒有出現

387
00:21:58,259 --> 00:22:00,298
全都寫成前綴編碼

388
00:22:00,298 --> 00:22:03,298
嚴格區分術語的話 大概是這樣

389
00:22:03,298 --> 00:22:06,618
在前綴編碼這個大類裡
霍夫曼編碼只是其中一種

390
00:22:06,618 --> 00:22:07,740
大概是這個概念

391
00:22:07,740 --> 00:22:12,920
而在 WebP 裡 霍夫曼編碼 
一律特指「範式霍夫曼編碼」
(Canonical Huffman Code)

392
00:22:12,920 --> 00:22:16,259
這些統稱為前綴編碼

393
00:22:16,259 --> 00:22:21,058
所以在這場演講裡 提到霍夫曼編碼

394
00:22:21,058 --> 00:22:23,798
都是指「範式霍夫曼編碼」

395
00:22:23,798 --> 00:22:25,098
先在這邊統一一下說法

396
00:22:25,098 --> 00:22:30,019
先從一般的霍夫曼法講起

397
00:22:30,019 --> 00:22:34,078
所謂壓縮是在做什麼呢

398
00:22:34,078 --> 00:22:38,180
就是把資料裡的冗餘資料 換成較短的表達方式

399
00:22:38,180 --> 00:22:40,000
冗餘有很多種

400
00:22:40,000 --> 00:22:41,640
在霍夫曼編碼裡

401
00:22:41,640 --> 00:22:44,180
利用統計上的偏差

402
00:22:44,180 --> 00:22:48,700
也就是常出現的值 和不常出現的值
之間的出現頻率偏差

403
00:22:48,700 --> 00:22:55,200
對於常出現的值
也就是高頻率的符號 (Symbol) 分配較短的碼

404
00:22:55,200 --> 00:22:59,960
對於出現頻率低的 符號就分配較長的碼

405
00:22:59,960 --> 00:23:01,358
這就是霍夫曼編碼

406
00:23:01,358 --> 00:23:05,660
在直接拿影像資料來做編碼之前

407
00:23:05,660 --> 00:23:08,519
先用一個簡單的字串當例子

408
00:23:08,519 --> 00:23:09,980
以 "BOOKKEEPER" 這個單字

409
00:23:09,980 --> 00:23:12,318
來做霍夫曼編碼的話

410
00:23:12,318 --> 00:23:15,420
第一步先統計各字母的出現頻率

411
00:23:15,420 --> 00:23:16,598
E 出現 3 次

412
00:23:16,598 --> 00:23:17,440
O 和 K 各 2 次

413
00:23:17,440 --> 00:23:19,318
B P R 各 1 次

414
00:23:19,318 --> 00:23:22,220
把它整理成表 按頻率排序

415
00:23:22,220 --> 00:23:23,759
左邊的是高頻

416
00:23:23,759 --> 00:23:25,118
因為有偏差

417
00:23:25,118 --> 00:23:28,618
也就是存在冗餘 所以能被壓縮

418
00:23:28,618 --> 00:23:31,200
越常出現的字 用越短的碼表示

419
00:23:31,200 --> 00:23:34,019
不常出現的字 就用較長的碼來表示

420
00:23:34,019 --> 00:23:36,140
步驟如下

421
00:23:36,140 --> 00:23:38,960
與其念步驟 直接看比較快

422
00:23:38,960 --> 00:23:41,160
我們直接來看

423
00:23:41,160 --> 00:23:44,660
先從頻率表直接

424
00:23:44,660 --> 00:23:47,618
建立葉節點 (leaf node)

425
00:23:47,618 --> 00:23:49,720
就是把每個符號照搬過來而已

426
00:23:49,720 --> 00:23:53,278
取出頻率最低的兩個符號

427
00:23:53,278 --> 00:23:55,240
組成一個二元分支

428
00:23:55,240 --> 00:23:56,298
不斷重複這個動作

429
00:23:56,298 --> 00:24:00,338
父節點的頻率 等於 葉節點頻率的總和

430
00:24:00,338 --> 00:24:04,480
父節點也會成為後續可合併的對象

431
00:24:04,480 --> 00:24:10,759
同樣地取出剩下的兩個 再建立二元樹

432
00:24:10,759 --> 00:24:12,838
接著再重複同樣的處理

433
00:24:12,838 --> 00:24:16,259
這裡因為比起 3 父節點的 2 較低

434
00:24:16,259 --> 00:24:19,618
所以 O 的 2 和那個父節點的 2
會成為合併對象

435
00:24:19,618 --> 00:24:21,920
就這樣合併起來

436
00:24:21,920 --> 00:24:29,900
之後就同樣重複 直到只剩一棵二元樹

437
00:24:29,900 --> 00:24:32,500
這樣就能得到一棵樹

438
00:24:32,500 --> 00:24:37,259
最初這棵樹長這樣

439
00:24:37,259 --> 00:24:40,798
這就叫作霍夫曼樹
(Huffman Tree)

440
00:24:40,798 --> 00:24:43,538
做好霍夫曼樹之後

441
00:24:43,538 --> 00:24:46,278
在左邊的分支給 0
右邊的分支給 1

442
00:24:46,278 --> 00:24:47,180
反過來也可以啦

443
00:24:47,180 --> 00:24:50,858
就是把左邊設 0
右邊的分支設 1 這樣分配

444
00:24:50,858 --> 00:24:53,778
然後從根一路走下去 就能得到碼

445
00:24:53,778 --> 00:24:58,140
比方說 E 是左、左 所以是 00 這個碼

446
00:24:58,140 --> 00:25:01,980
O 是右、左 所以是 10

447
00:25:01,980 --> 00:25:06,380
K 是左、右、左
所以會是 010 這個碼

448
00:25:06,380 --> 00:25:08,480
這樣碼就確定了

449
00:25:08,480 --> 00:25:12,259
出現頻率高的 會得到較短的碼

450
00:25:12,259 --> 00:25:13,278
大概就是這樣

451
00:25:13,278 --> 00:25:16,578
用這些碼把 "bookkeeper"
這個字串替換掉

452
00:25:16,578 --> 00:25:19,720
就可以像這樣表示 變成 25 位元

453
00:25:19,720 --> 00:25:23,278
假設字元集是從 A 到 Z

454
00:25:23,278 --> 00:25:25,858
表示 1 個字需要 5 位元

455
00:25:25,858 --> 00:25:28,380
原本 5×10 個字 等於需要 50 位元

456
00:25:28,380 --> 00:25:29,380
現在變成只要 25 位元

457
00:25:29,380 --> 00:25:30,818
也就是壓縮了 50% 容量

458
00:25:30,818 --> 00:25:32,660
原理就是這樣

459
00:25:32,660 --> 00:25:36,578
可能有些人剛剛也注意到了

460
00:25:36,578 --> 00:25:38,700
在一般的霍夫曼編碼裡

461
00:25:38,700 --> 00:25:40,960
碼的分配是有自由度的

462
00:25:40,960 --> 00:25:43,038
以剛剛的例子來說

463
00:25:43,038 --> 00:25:46,420
出現頻率相同的 R、B、P 的碼分配

464
00:25:46,420 --> 00:25:48,200
就算對調也不會改變壓縮率

465
00:25:48,200 --> 00:25:50,318
所以換來換去都可以

466
00:25:50,318 --> 00:25:53,180
不過因為碼的分配不一樣

467
00:25:53,180 --> 00:25:54,519
編碼結果就會不同

468
00:25:54,519 --> 00:25:57,838
因此要把編碼後的結果解碼

469
00:25:57,838 --> 00:26:00,460
就需要那張映射表 也就是碼表

470
00:26:00,460 --> 00:26:05,858
就算把碼表一起傳
只要要壓縮的資料夠大

471
00:26:05,858 --> 00:26:07,440
還是會有壓縮效果

472
00:26:07,440 --> 00:26:11,220
但如果規則是事先固定的

473
00:26:11,220 --> 00:26:14,880
就不需要送碼表了

474
00:26:14,880 --> 00:26:17,900
而要做的就是「把這種規則定下來」

475
00:26:17,900 --> 00:26:19,480
這就是範式霍夫曼編碼
(Canonical Huffman code)

476
00:26:19,480 --> 00:26:22,480
也稱為「範式霍夫曼」（正準ハフマン）

477
00:26:22,480 --> 00:26:26,420
範式霍夫曼編碼的規則就是這樣

478
00:26:26,420 --> 00:26:30,200
看例子最快 我們來試試看

479
00:26:30,200 --> 00:26:38,358
重點是 對於相同長度的碼
先把符號排序 然後依序賦予連號

480
00:26:38,358 --> 00:26:41,598
從樹的根往下走 會得到碼

481
00:26:41,598 --> 00:26:44,440
所以碼長就是樹的深度

482
00:26:44,440 --> 00:26:49,880
把同一深度的符號 按字典順序重新排列

483
00:26:49,880 --> 00:26:56,940
然後對每一組相同長度的 賦予連續的碼值

484
00:26:56,940 --> 00:26:58,038
規則就是這樣

485
00:26:58,038 --> 00:27:00,598
規範霍夫曼就是用這套規則來指定碼

486
00:27:00,598 --> 00:27:03,460
因此不需要共享樹或碼表

487
00:27:03,460 --> 00:27:09,578
解碼所需的只有
把依符號順序排列的碼長 傳過去就行

488
00:27:09,578 --> 00:27:13,798
這整套就是範式霍夫曼編碼的機制

489
00:27:13,798 --> 00:27:17,220
所以要解碼的話

490
00:27:17,220 --> 00:27:21,440
就是傳一個按照符號順序排好的碼長序列

491
00:27:21,440 --> 00:27:28,680
因為符號的順序是已知的
所以只要碼長即可

492
00:27:28,680 --> 00:27:33,880
如果不是範式霍夫曼編碼的話
想要傳遞這種霍夫曼編碼資料

493
00:27:33,880 --> 00:27:37,038
就得把樹的形狀和葉節點也傳過去

494
00:27:37,038 --> 00:27:41,380
乍看之下 範式霍夫曼編碼好像會多送資料

495
00:27:41,380 --> 00:27:46,358
當使用的符號變多時 成本會反轉

496
00:27:46,358 --> 00:27:48,660
但重點不在這裡

497
00:27:48,660 --> 00:27:51,858
範式霍夫曼編碼厲害的地方在於

498
00:27:51,858 --> 00:27:56,220
看這個碼長序列 大部分項目都是 0

499
00:27:56,220 --> 00:28:02,058
其他不是 0 的部分 在這個例子也很容易看懂
就只有 2 和 3 而已

500
00:28:02,058 --> 00:28:03,680
「只需要傳送碼長」這件事

501
00:28:03,680 --> 00:28:08,358
等於把資料轉換成了
有利於霍夫曼編碼的形式 就是這樣

502
00:28:08,358 --> 00:28:13,598
實際上在 WebP 裡 還會把這個碼長
再用霍夫曼編碼壓縮一次

503
00:28:13,598 --> 00:28:18,900
WebP 編碼裡用到的碼長 最多也就 15

504
00:28:18,900 --> 00:28:22,200
跟像素可能取到各種變化值相比 範圍小很多

505
00:28:22,200 --> 00:28:25,240
所有數值都會緊密集中在較小的數字

506
00:28:25,240 --> 00:28:28,298
而且也會大量出現未使用的 0

507
00:28:28,298 --> 00:28:30,818
因此壓縮效果非常好

508
00:28:30,818 --> 00:28:33,500
我們就是想做出這樣的資料

509
00:28:33,500 --> 00:28:37,220
這也就是「範式霍夫曼編碼」的真正目的

510
00:28:37,220 --> 00:28:40,259
不是「普通的霍夫曼編碼」喔

511
00:28:40,259 --> 00:28:42,440
總結一下霍夫曼編碼

512
00:28:42,440 --> 00:28:45,278
它是利用出現頻率偏差來壓縮

513
00:28:45,278 --> 00:28:48,500
在 WebP 中用的是範式霍夫曼編碼

514
00:28:48,500 --> 00:28:50,940
所謂範式霍夫曼編碼

515
00:28:50,940 --> 00:28:53,980
是一種只要知道符碼長度(code length)
就能解碼的方法

516
00:28:53,980 --> 00:28:56,500
而這個「符碼長度序列」本身重複率高、特性穩定

517
00:28:56,500 --> 00:28:58,759
也非常適合再用霍夫曼編碼
來進一步壓縮

518
00:28:58,759 --> 00:29:04,838
也就是說 在 WebP 裡
這些符碼長度序列 也會被再做過霍夫曼編碼
形成一種「多層」或「雙重」的霍夫曼結構

519
00:29:04,838 --> 00:29:11,078
這既是難點之一 也是關鍵所在

520
00:29:11,078 --> 00:29:16,818
從微觀角度看
會對相似的資料 多次套用霍夫曼編碼

521
00:29:16,818 --> 00:29:19,380
就會有點搞不清楚現在在做什麼

522
00:29:19,380 --> 00:29:22,278
真的在寫的時候 很容易迷路

523
00:29:22,278 --> 00:29:22,980
這是其一

524
00:29:22,980 --> 00:29:26,500
另外從宏觀來看 這個 WebP 的流程

525
00:29:26,500 --> 00:29:29,838
反正最後一定會套用霍夫曼編碼

526
00:29:29,838 --> 00:29:34,420
為了把霍夫曼編碼的效果發揮到最大

527
00:29:34,420 --> 00:29:39,298
你甚至可以把 WebP 的處理流程
都看成是為了霍夫曼編碼設計的

528
00:29:39,298 --> 00:29:40,778
這樣理解也不算錯

529
00:29:40,778 --> 00:29:45,220
因為最後一定會套用霍夫曼編碼

530
00:29:45,220 --> 00:29:47,358
那在此之前 就在可復原的範圍內

531
00:29:47,358 --> 00:29:52,078
將資料調整成
「能用霍夫曼編碼最高效壓縮」的形式
這就是 VP（VP8L）解編碼器的最大目的

532
00:29:52,078 --> 00:29:54,038
理解了這點之後

533
00:29:54,038 --> 00:29:59,240
就會慢慢看懂 VP 解編碼器
那些複雜的機制和處理流程

534
00:29:59,240 --> 00:30:04,380
把實際的圖片拿來做霍夫曼編碼會怎麼樣呢

535
00:30:04,380 --> 00:30:07,240
這有點靠直覺啦

536
00:30:07,240 --> 00:30:11,858
在 VP8L 內部
是用圖片的 RGBA 四個通道當作成員

537
00:30:11,858 --> 00:30:16,259
會對每個成員 分別做霍夫曼編碼

538
00:30:16,259 --> 00:30:21,400
所謂出現次數
就是指 RGBA 各成員的出現頻率

539
00:30:21,400 --> 00:30:25,118
例如只看綠色部分

540
00:30:25,118 --> 00:30:30,920
出現的數值大概長這樣
頻率分布大概是這樣

541
00:30:30,920 --> 00:30:35,460
把特別常見的 206 設成比較短的符號

542
00:30:35,460 --> 00:30:36,019
也就是用短碼來表示

543
00:30:36,019 --> 00:30:39,380
而 0 69 105 這些
就用比較長的碼去編碼

544
00:30:39,380 --> 00:30:41,400
這樣就是霍夫曼編碼

545
00:30:41,400 --> 00:30:45,140
在沒有做任何前置處理時

546
00:30:45,140 --> 00:30:46,740
只是單純的一張圖片

547
00:30:46,740 --> 00:30:50,480
就算只做霍夫曼編碼 看這個就會發現

548
00:30:50,480 --> 00:30:52,759
一旦按成員拆開 就有不少幾乎沒被用到的符號

549
00:30:52,759 --> 00:30:54,460
分布偏差其實很明顯

550
00:30:54,460 --> 00:30:57,558
正因為這樣 就能壓縮得非常小

551
00:30:57,558 --> 00:30:58,900
編碼後會變成這樣

552
00:30:58,900 --> 00:31:01,078
像 206 幾乎只要用 0

553
00:31:01,078 --> 00:31:02,818
就能把它表達出來

554
00:31:02,818 --> 00:31:04,558
容量就會大幅下降

555
00:31:04,558 --> 00:31:08,118
這是實際圖片的大小

556
00:31:08,118 --> 00:31:11,420
這張是 16×16 所以本來就很小

557
00:31:11,420 --> 00:31:15,700
跟真實狀況的圖片比還是有不小差異

558
00:31:15,700 --> 00:31:19,880
即便如此 不壓縮也有 1302 bytes

559
00:31:19,880 --> 00:31:23,759
光套個簡單的霍夫曼編碼
就能壓縮到 384 bytes

560
00:31:23,759 --> 00:31:29,838
實際上我們還會做一些轉換 讓壓縮效率更高

561
00:31:29,838 --> 00:31:32,240
就算只看剛剛的綠色部分

562
00:31:32,240 --> 00:31:35,700
雖然只靠綠色部分 也已經能壓得很小

563
00:31:35,700 --> 00:31:38,980
但這樣做 還能更進一步壓縮

564
00:31:38,980 --> 00:31:42,460
先把霍夫曼編碼再整理一下

565
00:31:42,460 --> 00:31:49,318
實際狀況下的圖片資料中 會大量出現某些符號

566
00:31:49,318 --> 00:31:54,240
而且按成員分開 特別是按 RGB 分開看的話
分布偏差非常明顯

567
00:31:54,240 --> 00:31:56,400
所以霍夫曼編碼會非常有效

568
00:31:56,400 --> 00:32:00,980
另外在 WebP 裡
為了進一步強化霍夫曼編碼的效果

569
00:32:00,980 --> 00:32:04,140
會在前期處理階段套用各種轉換
這就是 WebP 的實際作法

570
00:32:04,140 --> 00:32:08,440
而其中只有霍夫曼編碼是必須步驟

571
00:32:08,440 --> 00:32:13,920
沒做霍夫曼編碼的資料
就不會被當成 WebP

572
00:32:13,920 --> 00:32:16,098
所以也正因為這樣

573
00:32:16,098 --> 00:32:20,880
只要先把霍夫曼編碼做好
在規格上就算是正確的 WebP

574
00:32:20,880 --> 00:32:24,618
其他檢視器也能當作 WebP 讀取

575
00:32:24,618 --> 00:32:29,078
雖然霍夫曼編碼會出現兩次以上

576
00:32:29,078 --> 00:32:30,660
這點比較讓人困惑

577
00:32:30,660 --> 00:32:35,980
不過這邊搞定之後
剩下就照順序一個個實作下去就好

578
00:32:35,980 --> 00:32:40,358
把它實作完 其實離終點就不遠了

579
00:32:40,358 --> 00:32:45,019
這邊我們再回頭看一次整個編碼流程

580
00:32:45,019 --> 00:32:47,538
應該會比剛才更清楚一點

581
00:32:47,538 --> 00:32:51,318
必須的步驟
只有這個紅色的霍夫曼編碼

582
00:32:51,318 --> 00:32:55,380
有這個再加上 header
基本上就能被當作 WebP 圖片來辨識

583
00:32:55,380 --> 00:32:58,900
就算不做投影片上綠色的步驟
只是要產生 WebP 圖片也沒問題

584
00:32:58,900 --> 00:33:01,640
綠框的部分都是可選的處理步驟

585
00:33:01,640 --> 00:33:04,858
目的是讓霍夫曼編碼更高效

586
00:33:04,858 --> 00:33:06,858
也就是所謂的前期處理

587
00:33:06,858 --> 00:33:08,318
大概就是這樣

588
00:33:08,318 --> 00:33:11,200
接下來就一一看剩下那些綠色的處理

589
00:33:11,200 --> 00:33:14,000
首先是對綠色做圖形減法運算
(Subtract Green)

590
00:33:14,000 --> 00:33:17,778
以綠色為基準 把多餘的部分扣掉

591
00:33:17,778 --> 00:33:23,278
建議做完霍夫曼編碼流程之後

592
00:33:23,278 --> 00:33:25,798
下一步就做這個步驟

593
00:33:25,798 --> 00:33:33,220
這個步驟是對每個像素
從紅色與藍色分量中 減去綠色

594
00:33:33,220 --> 00:33:37,298
藉此降低色彩分量的相關性
是能讓壓縮更高效的一種作法

595
00:33:37,298 --> 00:33:40,400
這個步驟真的就只是「相減」而已 非常簡單

596
00:33:40,400 --> 00:33:42,700
做起來很容易

597
00:33:42,700 --> 00:33:45,480
只要從紅色與藍色中 減去綠色就可以了

598
00:33:45,480 --> 00:33:48,578
如果色彩數值太小導致下溢 (underflow)
會自動回繞到範圍內 (wraparound)

599
00:33:48,578 --> 00:33:51,900
為什麼要減去綠色呢

600
00:33:51,900 --> 00:33:54,740
這要從大多圖片可以拆成
「明度」和「彩度」來思考

601
00:33:54,740 --> 00:33:57,980
明度的差異通常很大

602
00:33:57,980 --> 00:33:59,239
而彩度差異通常比較小

603
00:33:59,239 --> 00:34:00,699
所以我們想把明度那一塊削掉

604
00:34:00,699 --> 00:34:05,880
人眼對綠色最敏感 最容易感到明度

605
00:34:05,880 --> 00:34:10,320
在一般的色彩空間裡
綠色多半承擔了明度的成分

606
00:34:10,320 --> 00:34:13,940
因此從紅和藍裡把綠扣掉

607
00:34:13,940 --> 00:34:18,018
共同的明度部分會被抵銷
只剩下色差（彩度差）

608
00:34:18,018 --> 00:34:26,300
而色差一般不會太大 分布就會更集中
於是更容易壓縮

609
00:34:26,300 --> 00:34:28,018
解碼則相反

610
00:34:28,018 --> 00:34:31,079
我們雖然在紅色和藍色中扣掉了綠

611
00:34:31,079 --> 00:34:32,760
但綠本身是原封不動留著的

612
00:34:32,760 --> 00:34:35,960
解碼時把留下來的綠色加回去就好

613
00:34:35,960 --> 00:34:37,559
很簡單對吧

614
00:34:37,559 --> 00:34:42,880
後面的流程也會讓人覺得這方法很不錯

615
00:34:42,880 --> 00:34:47,659
因為綠色還是保留著 直接拿來相加就行

616
00:34:47,659 --> 00:34:49,579
我自己覺得這點還挺有趣的

617
00:34:49,579 --> 00:34:52,940
我們實際來看一下效果

618
00:34:52,940 --> 00:34:57,960
這招對那種色調偏灰的圖特別有效

619
00:34:57,960 --> 00:35:00,840
因為灰色基本上就是明度占大宗

620
00:35:00,840 --> 00:35:03,340
如果是純灰階 做了綠色減法運算之後

621
00:35:03,340 --> 00:35:04,340
這些分量會全部變成 0

622
00:35:04,340 --> 00:35:08,679
RGB 的數值大概會變成這樣

623
00:35:08,679 --> 00:35:09,860
實際上就是這個顏色

624
00:35:09,860 --> 00:35:14,119
把紅和藍都減去綠的話

625
00:35:14,119 --> 00:35:18,559
大多數數值會落在 3 到 6 之間
變成非常非常小的值

626
00:35:18,559 --> 00:35:21,000
數值分布會緊密地集中到 0 附近

627
00:35:21,000 --> 00:35:25,639
這樣一來
霍夫曼編碼的效果就會變得非常好

628
00:35:25,639 --> 00:35:29,320
這就是叫做「減去綠色」的前期處理

629
00:35:29,320 --> 00:35:32,320
也就是說 雖然它不一定對整張圖都有效

630
00:35:32,320 --> 00:35:34,900
但像是這種地面的顏色

631
00:35:34,900 --> 00:35:36,518
或是陰天的天空這種顏色

632
00:35:36,518 --> 00:35:40,059
一定會出現這種顏色連續的區域

633
00:35:40,059 --> 00:35:44,420
在那類影像上 這種前期處理就特別有效

634
00:35:44,420 --> 00:35:48,460
另外還會用到的是 LZ77 演算法

635
00:35:48,460 --> 00:35:53,420
它是透過用「距離與長度」來表達重複模式
藉此壓縮的機制

636
00:35:53,420 --> 00:35:57,920
把這張圖用 LZ77 來編碼的話

637
00:35:57,920 --> 00:36:04,079
在讀取的過程中 遇到連續的模式
就會把它記錄下來

638
00:36:04,079 --> 00:36:07,099
有點像「快取」的概念，會記住過去出現過的資料

639
00:36:07,099 --> 00:36:11,340
每讀一段就去比對看看
是否和過去的模式一致

640
00:36:11,340 --> 00:36:14,460
但如果對所有像素都做比對會太耗時

641
00:36:14,460 --> 00:36:17,400
所以每 3 個像素比對一次即可

642
00:36:17,400 --> 00:36:21,820
之所以是 3 個像素
是因為規格規定壓縮長度至少為 3

643
00:36:21,820 --> 00:36:24,360
那樣會是效率最好的

644
00:36:24,360 --> 00:36:26,900
如果又出現和某個模式相同的片段

645
00:36:26,900 --> 00:36:29,820
就會去看這個模式能連續到什麼程度

646
00:36:29,820 --> 00:36:31,039
能延伸就一直往前走

647
00:36:31,039 --> 00:36:33,400
直到模式的連續性被打斷的地方

648
00:36:33,400 --> 00:36:37,400
就會記錄成從前面第 15 個像素開始

649
00:36:37,400 --> 00:36:41,900
往後 5 個都是同樣的模式這樣的資訊

650
00:36:41,900 --> 00:36:48,539
也就是可以用像 "15,3"
這樣的另一種表達來替換

651
00:36:48,539 --> 00:36:51,480
這就是所謂的 LZ77 演算法

652
00:36:51,480 --> 00:36:55,139
這個與其說
是為了霍夫曼編碼的轉換

653
00:36:55,139 --> 00:36:59,119
不如說是拿來處理霍夫曼編碼
壓縮不了的那些部分

654
00:36:59,119 --> 00:37:02,000
霍夫曼編碼是根據機率分佈來壓縮

655
00:37:02,000 --> 00:37:04,440
但像重複模式這種東西

656
00:37:04,440 --> 00:37:07,079
霍夫曼編碼其實派不上用場

657
00:37:07,079 --> 00:37:11,000
所以才需要用它來壓縮那些
霍夫曼編碼不擅長的重複性或模式

658
00:37:11,000 --> 00:37:13,440
算是一種互補手段

659
00:37:13,440 --> 00:37:16,360
可以把 LZ77 看成是這樣的一種壓縮方法

660
00:37:16,360 --> 00:37:20,159
接下來是「預測轉換」
(Predictor Transform)

661
00:37:20,159 --> 00:37:22,559
它是用左邊和上方的顏色資訊
來推測下一個顏色

662
00:37:22,559 --> 00:37:27,340
利用左邊、左上以及上方相鄰的像素

663
00:37:27,340 --> 00:37:30,360
目前這個像素色彩
大致上會落在相近的範圍

664
00:37:30,360 --> 00:37:33,480
就去預測它可能會是什麼值

665
00:37:33,480 --> 00:37:35,639
然後只記錄預測值和實際值之間的差

666
00:37:35,639 --> 00:37:39,559
也就是取差值 並只把差值記下來的轉換

667
00:37:39,559 --> 00:37:43,639
比方說現在已經把暗部的像素讀到這裡

668
00:37:43,639 --> 00:37:44,619
而且都已經編碼了

669
00:37:44,619 --> 00:37:47,039
接著要讀這個紅框的區域

670
00:37:47,039 --> 00:37:51,800
準備把它編碼時 就會去預估這個像素的值

671
00:37:51,800 --> 00:37:55,500
根據相鄰的左、左上以及上方的像素 來做預測

672
00:37:55,500 --> 00:37:59,800
雖然說是預測 其實準不準並不是重點

673
00:37:59,800 --> 00:38:04,119
重點是取差之後
把值盡量變小（減少熵值）

674
00:38:04,119 --> 00:38:06,139
這樣分佈就會更集中

675
00:38:06,139 --> 00:38:09,880
當然預測越接近越好

676
00:38:09,880 --> 00:38:14,719
所以就用一些看起來合理的
也不完全只是經驗法則

677
00:38:14,719 --> 00:38:17,000
但能讓結果接近的函式

678
00:38:17,000 --> 00:38:19,039
在規格書裡 預先定了 14 種

679
00:38:19,039 --> 00:38:23,139
會套用它們 然後挑出表現最好的那一個

680
00:38:23,139 --> 00:38:24,760
說到底 其實怎樣都行

681
00:38:24,760 --> 00:38:29,159
用什麼值都可以 只要相減之後變小就行

682
00:38:29,159 --> 00:38:31,420
當然這個函式是共享的

683
00:38:31,420 --> 00:38:35,518
解碼端也會用同一個函式來把它解回來

684
00:38:35,518 --> 00:38:39,960
色彩轉換 (Cross Color)
會把顏色之間的混色拆開

685
00:38:39,960 --> 00:38:42,300
減少紅色和藍色的波動

686
00:38:42,300 --> 00:38:44,699
這是什麼意思呢

687
00:38:44,699 --> 00:38:47,960
做法是先把圖稍微切成區塊

688
00:38:47,960 --> 00:38:49,440
在那裡乘上一些係數

689
00:38:49,440 --> 00:38:53,800
本質上還是從紅色和藍色裡 減掉綠色

690
00:38:53,800 --> 00:38:56,579
但和前面的減去綠色 不同的是

691
00:38:56,579 --> 00:39:01,420
它更著重在把小幅的色彩抖動降下來

692
00:39:01,420 --> 00:39:09,860
像草地或日本人的膚色那種
顏色有點細碎閃爍 互相摻在一起的

693
00:39:09,860 --> 00:39:15,960
在這類影像上能把色彩分布大幅收斂

694
00:39:15,960 --> 00:39:18,760
就是那種顏色有點暈開的區域

695
00:39:18,760 --> 00:39:20,860
對這些地方特別有效

696
00:39:20,860 --> 00:39:23,480
再來是「色彩索引」
(Color Indexing)

697
00:39:23,480 --> 00:39:27,219
當影像使用的顏色不超過 256 種時

698
00:39:27,219 --> 00:39:30,559
就替每個顏色編號 改用編號來寫

699
00:39:30,559 --> 00:39:33,840
只要在 256 色以下就能用

700
00:39:33,840 --> 00:39:36,860
算是一種壓縮絕招

701
00:39:36,860 --> 00:39:38,719
因為把所有顏色都換成編號了

702
00:39:38,719 --> 00:39:40,480
原本紀錄色彩資訊的那些地方

703
00:39:40,480 --> 00:39:49,079
資訊量就會大幅縮小 達到壓縮效果

704
00:39:49,079 --> 00:39:51,440
最後是「色彩快取」
(Color Cache)

705
00:39:51,440 --> 00:39:52,679
這個滿有趣的

706
00:39:52,679 --> 00:39:54,500
會把出現過的顏色先快取起來

707
00:39:54,500 --> 00:39:56,920
之後再出現相同的顏色時
只留下快取的索引

708
00:39:56,920 --> 00:39:59,300
其實就是做了一個本機快取

709
00:39:59,300 --> 00:40:02,860
放在本機記憶體裡的快取

710
00:40:02,860 --> 00:40:04,980
本機端把出現過的東西放進快取

711
00:40:04,980 --> 00:40:07,480
下次如果剛好在快取裡有

712
00:40:07,480 --> 00:40:08,820
如果只把那個快取的索引送出去的話

713
00:40:08,820 --> 00:40:10,559
會想說 這不就是本機快取嗎

714
00:40:10,559 --> 00:40:13,460
就算把本機快取的資訊送過去

715
00:40:13,460 --> 00:40:17,460
這個 就算送給對方也不可能解碼吧

716
00:40:17,460 --> 00:40:18,079
會這樣想的啦

717
00:40:18,079 --> 00:40:20,980
其實解碼也能做一樣的事喔

718
00:40:20,980 --> 00:40:22,340
一邊做編碼

719
00:40:22,340 --> 00:40:25,059
把編碼過的東西放進快取

720
00:40:25,059 --> 00:40:26,599
啊不是 是解碼啦

721
00:40:26,599 --> 00:40:29,280
一邊解碼 把已解碼的東西放進快取

722
00:40:29,280 --> 00:40:31,179
這樣一來就編碼完成了

723
00:40:31,179 --> 00:40:33,159
所以如果收到「這個是從快取來的喔」
這樣的資訊

724
00:40:33,159 --> 00:40:35,920
它就在快取裡 所以可以直接從那裡取用

725
00:40:35,920 --> 00:40:38,018
我覺得這點超有趣

726
00:40:38,018 --> 00:40:41,559
當然快取要怎麼做

727
00:40:41,559 --> 00:40:42,679
裡面也各自有些訣竅啦

728
00:40:42,679 --> 00:40:44,739
雖然是本機快取

729
00:40:44,739 --> 00:40:47,039
但還是要按順序讀取 這點是一樣的

730
00:40:47,039 --> 00:40:51,980
只靠快取的索引就能解碼
這件事我覺得真的很有趣

731
00:40:51,980 --> 00:40:53,639
這個做得很不錯

732
00:40:53,639 --> 00:40:54,579
就是一種壓縮方式啦

733
00:40:54,579 --> 00:40:57,360
不過它很簡單 所以實作也很簡單

734
00:40:57,360 --> 00:41:03,219
總結一下 總之希望大家會覺得
「喔這個還挺有意思的」就好啦

735
00:41:03,219 --> 00:41:07,139
目前為止 簡單說明了 WebP 的原理和機制

736
00:41:07,139 --> 00:41:09,780
雖然不是那種很酷炫的 UI 程式碼

737
00:41:09,780 --> 00:41:12,880
可能不至於讓你馬上想動手試試看

738
00:41:12,880 --> 00:41:15,400
但關於圖片的壓縮機制

739
00:41:15,400 --> 00:41:19,400
尤其是剛剛看到的無損壓縮
其實是很追求合理性的

740
00:41:19,400 --> 00:41:23,420
如果能讓你覺得這是一套很優美的機制
我會很開心

741
00:41:23,420 --> 00:41:27,059
資料壓縮的思維 不只用在圖片上

742
00:41:27,059 --> 00:41:28,780
對各種資料處理也很有幫助

743
00:41:28,780 --> 00:41:31,940
接觸過一次 記住有各種不同手法之後

744
00:41:31,940 --> 00:41:33,980
我想會是個很能拓展視野的領域

745
00:41:33,980 --> 00:41:36,619
作為下一步

746
00:41:36,619 --> 00:41:38,880
把範例裡提供的編碼器

747
00:41:38,880 --> 00:41:40,800
稍微做點最佳化會不錯

748
00:41:40,800 --> 00:41:45,780
範例裡 編碼器在大多數情況
都是固定成只有一種

749
00:41:45,780 --> 00:41:50,500
但其實編碼器呢
會依照圖片決定要套用什麼轉換

750
00:41:50,500 --> 00:41:55,018
也會更換方式或調整參數
來讓檔案變得更小

751
00:41:55,018 --> 00:42:01,159
所以就做這些事 嘗試各種調整
量測結果 進行比對

752
00:42:01,159 --> 00:42:04,219
如果能讓容量變得更小之類的
應該也會有不少新發現

753
00:42:04,219 --> 00:42:05,119
我想會蠻有趣的

754
00:42:05,119 --> 00:42:10,179
像這樣建立假設 執行 再驗證
是正統的改善方法

755
00:42:10,179 --> 00:42:14,880
好好走一遍這樣的循環
應該會蠻不錯的

756
00:42:14,880 --> 00:42:19,039
如果覺得今天的內容有趣 哪怕只是一點點

757
00:42:19,039 --> 00:42:20,360
我就很開心了

758
00:42:20,360 --> 00:42:22,280
非常感謝大家

759
00:42:28,820 --> 00:42:30,983
感謝您的發表

760
00:42:31,300 --> 00:42:33,800
那接下來進入 Q&A 環節

761
00:42:33,800 --> 00:42:37,119
有意見或想問問題的人請舉手

762
00:42:45,659 --> 00:42:48,980
好的 那 Q&A 就到此結束

763
00:42:48,980 --> 00:42:52,119
接下來是 1 分鐘回饋時間

764
00:42:52,119 --> 00:43:08,000
翻譯：Hokila
校對：@Mori_Liu

