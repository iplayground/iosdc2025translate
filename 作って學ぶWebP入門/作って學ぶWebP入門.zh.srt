1
00:00:00,000 --> 00:00:02,520
邊做邊學 WebP 入門

2
00:00:02,520 --> 00:00:07,360
岸川克己

3
00:00:07,360 --> 00:00:18,379
大家好，我是岸川克己。

4
00:00:18,379 --> 00:00:22,739
今天要和大家一起學習一種叫做 WebP 的影像格式是怎麼運作的。

5
00:00:22,739 --> 00:00:27,500
不只限於軟體，要理解任何東西的原理或機制，最快的捷徑就是

6
00:00:27,500 --> 00:00:29,339
親手做做看。

7
00:00:29,339 --> 00:00:34,859
所以這次我們會動手實作 WebP 的編解碼器，

8
00:00:34,859 --> 00:00:37,659
來理解它的資料結構與壓縮原理。

9
00:00:37,659 --> 00:00:42,719
所謂編解碼器（codec）就是把編碼器（encoder）和解碼器（decoder）合在一起的稱呼。

10
00:00:42,719 --> 00:00:45,979
是 encoder 和 decoder 兩個字的組合。

11
00:00:45,979 --> 00:00:49,340
雖說是邊做邊學，

12
00:00:49,340 --> 00:00:52,380
對大多數人來說，實作 WebP 很難，

13
00:00:52,380 --> 00:00:55,200
常常會搞不清楚自己到底在做什麼。

14
00:00:55,200 --> 00:01:01,119
因此這場演講的目的，就是幫你排除這些學習障礙。

15
00:01:01,119 --> 00:01:06,239
WebP 的實作之所以難，其中一個原因是

16
00:01:06,239 --> 00:01:13,319
首先，規格書基本上是預設你已經懂影像格式和壓縮技術，

17
00:01:13,319 --> 00:01:19,040
沒有那些前置知識的話，光看規格書根本看不出在做什麼。

18
00:01:19,040 --> 00:01:23,920
你可能會想「實作協定不就是照著規格書寫嗎？」

19
00:01:23,920 --> 00:01:26,859
一開始我也這麼想，

20
00:01:26,859 --> 00:01:28,859
但事實並不是這樣。

21
00:01:28,859 --> 00:01:31,459
那就來讀程式碼吧。

22
00:01:31,459 --> 00:01:34,060
以為讀了就會懂，

23
00:01:34,060 --> 00:01:40,180
可以參考的 WebP 實作基本上只有那個用 C 語言寫的 WebP 官方實作，

24
00:01:40,180 --> 00:01:45,219
而那份實作裡面為了最佳化、平行處理的分支等等，

25
00:01:45,219 --> 00:01:48,819
在很多非本質的地方規模變得很大、相當複雜，

26
00:01:48,819 --> 00:01:51,900
拿來學習其實不太適合。

27
00:01:51,900 --> 00:01:55,019
再說，壓縮演算法

28
00:01:55,019 --> 00:01:58,219
和一般的程式設計思路差很多，

29
00:01:58,219 --> 00:02:00,700
在還沒理解原理的階段去讀，

30
00:02:00,700 --> 00:02:01,819
是很困難的。

31
00:02:01,819 --> 00:02:04,159
所以不管你看規格或看程式碼，

32
00:02:04,159 --> 00:02:07,739
都很難抓到到底在做什麼，

33
00:02:07,739 --> 00:02:09,240
這就是第一道門檻。

34
00:02:09,240 --> 00:02:12,900
就算好不容易跨過這道障礙，

35
00:02:12,900 --> 00:02:17,460
把規格讀懂、準備開始實作，

36
00:02:17,460 --> 00:02:21,919
即便如此，沒有非常強的動力的話，

37
00:02:21,919 --> 00:02:24,680
大概很快就會半途而廢。

38
00:02:24,680 --> 00:02:29,860
因為 WebP 的機制是由許多小步驟堆疊起來，

39
00:02:29,860 --> 00:02:32,280
最後讓檔案變小的一套流程。

40
00:02:32,280 --> 00:02:33,379
大致上就是這樣的機制。

41
00:02:33,379 --> 00:02:38,240
而壓縮或解碼這類處理是非黑即白的，

42
00:02:38,240 --> 00:02:40,960
就算你實作得沒錯，

43
00:02:40,960 --> 00:02:44,699
在半成品階段也完全不會顯示出任何圖片。

44
00:02:44,699 --> 00:02:47,560
所以想確認結果，

45
00:02:47,560 --> 00:02:51,340
就得把整個流程從頭到尾全部先做完。

46
00:02:51,340 --> 00:02:54,580
但各個步驟彼此相依，

47
00:02:54,580 --> 00:02:56,939
因為各階段都和後續階段互相依賴，

48
00:02:56,939 --> 00:03:00,900
很難把它們一個個獨立驗證。

49
00:03:00,900 --> 00:03:06,120
換句話說，就像在一片看不清前路的森林裡，

50
00:03:06,120 --> 00:03:08,580
走一段很長的路，

51
00:03:08,580 --> 00:03:11,199
寫著寫著也不知道自己到底對不對，

52
00:03:11,199 --> 00:03:13,580
老是懷疑「這有對嗎？」，

53
00:03:13,580 --> 00:03:16,599
一路寫到最後才砰的一聲驗證，

54
00:03:16,599 --> 00:03:20,080
然後發現不行…常會變成這樣。

55
00:03:20,080 --> 00:03:23,419
能一直撐下去的人其實不多。

56
00:03:23,419 --> 00:03:29,740
所以在這場演講中，我們先把壓縮率等細節都暫時擱一邊，

57
00:03:29,740 --> 00:03:35,259
先做出一張「只要能被當成 WebP 圖片識別」就好的

58
00:03:35,259 --> 00:03:38,500
超級精簡的最小實作原型。

59
00:03:38,500 --> 00:03:44,139
接著再配上一個能把它解碼的解碼器，一起準備好。

60
00:03:44,139 --> 00:03:46,900
以此為基礎，一個一個加功能，

61
00:03:46,900 --> 00:03:51,020
每加一個，這邊能顯示圖片、那邊也能解碼，

62
00:03:51,020 --> 00:03:54,979
再加一個，同樣地反覆確認，

63
00:03:54,979 --> 00:03:59,819
如此就能逐步地、局部地確認

64
00:03:59,819 --> 00:04:04,840
每個實作是否正確，建立起一步一步的驗證流程來推進。

65
00:04:04,840 --> 00:04:09,159
這樣最終就能做出一個完整功能的 WebP 編解碼器。

66
00:04:09,159 --> 00:04:13,020
為了做到這件事，我準備了一些東西，

67
00:04:13,020 --> 00:04:15,219
而這場演講最重要的，

68
00:04:15,219 --> 00:04:19,100
就是我為此準備的範例程式碼

69
00:04:19,100 --> 00:04:23,899
也就是那個最小實作的範例程式碼，

70
00:04:23,899 --> 00:04:25,699
以及測試資料。

71
00:04:25,699 --> 00:04:28,100
我覺得這大概是最重要的，

72
00:04:28,100 --> 00:04:29,980
比我現在講的內容還重要。

73
00:04:29,980 --> 00:04:32,180
用 Swift 寫的 WebP 編解碼器，

74
00:04:32,180 --> 00:04:34,180
市面上根本不存在，

75
00:04:34,180 --> 00:04:35,240
目前就只有這個。

76
00:04:35,240 --> 00:04:39,860
而且還特地為學習用途，盡量不使用多餘的技巧，

77
00:04:39,860 --> 00:04:42,420
這種寫法真的就只有這個，

78
00:04:42,420 --> 00:04:47,040
所以我覺得這次做出來的東西還不錯。

79
00:04:47,040 --> 00:04:51,120
範例程式碼已經在這個 repository 上公開，

80
00:04:51,120 --> 00:04:52,079
應該看得到。

81
00:04:52,079 --> 00:04:57,300
這次的內容大致如下：

82
00:04:57,300 --> 00:04:59,240
首先，先來講 WebP，

83
00:04:59,240 --> 00:05:01,199
可能有些人不太熟，

84
00:05:01,199 --> 00:05:02,420
我會先快速複習一下。

85
00:05:02,420 --> 00:05:07,980
然後也會提一下在 iOS 上能不能用 WebP 之類的話題，

86
00:05:07,980 --> 00:05:10,500
接著談談資料結構，

87
00:05:10,500 --> 00:05:13,819
一邊介紹，一邊實際讀讀看檔案，

88
00:05:13,819 --> 00:05:16,920
還有最小實作，

89
00:05:16,920 --> 00:05:19,480
以及產生壓縮資料，

90
00:05:19,480 --> 00:05:21,240
在學 WebP 時會用到的

91
00:05:21,240 --> 00:05:22,839
高效資料壓縮技術，

92
00:05:22,839 --> 00:05:24,139
我也會一路穿插著說明。

93
00:05:24,139 --> 00:05:26,519
最後做個總結與下一步建議，

94
00:05:26,519 --> 00:05:28,579
回顧學到什麼，

95
00:05:28,579 --> 00:05:30,759
以及接下來做些什麼會比較有趣，

96
00:05:30,759 --> 00:05:31,800
也都會聊到。

97
00:05:31,800 --> 00:05:35,319
那就先來複習一下 WebP。

98
00:05:35,319 --> 00:05:36,800
WebP 是什麼？

99
00:05:36,800 --> 00:05:39,600
WebP 是一種在網站或應用上

100
00:05:39,600 --> 00:05:41,959
很適合用來顯示的影像格式。

101
00:05:41,959 --> 00:05:44,740
這裡說的「適合」是什麼意思呢？

102
00:05:44,740 --> 00:05:46,399
追根究柢，這個格式開發的動機就是

103
00:05:46,399 --> 00:05:47,759
比起其他格式，

104
00:05:47,759 --> 00:05:49,680
盡可能把資料容量壓到最小，

105
00:05:49,680 --> 00:05:51,639
一開始就是以此為目的來開發的，

106
00:05:51,639 --> 00:05:53,579
也就是說是透過網路

107
00:05:53,579 --> 00:05:55,120
進行傳送與接收的

108
00:05:55,120 --> 00:05:56,240
情境下來設想的。

109
00:05:56,240 --> 00:05:59,720
從一開始就支援 Alpha 通道，

110
00:05:59,720 --> 00:06:02,120
標準就能做背景透明之類的，

111
00:06:02,120 --> 00:06:04,079
另外也支援動畫，

112
00:06:04,079 --> 00:06:05,639
所以像圖示、

113
00:06:05,639 --> 00:06:08,759
UI 元素等都很好用，

114
00:06:08,759 --> 00:06:10,920
也就是說它是一個好上手的格式。

115
00:06:10,920 --> 00:06:12,620
到這裡為止，

116
00:06:12,620 --> 00:06:15,120
我想很多人應該都知道。

117
00:06:15,120 --> 00:06:17,920
但其實有個 WebP 不太被注意到的特性是，

118
00:06:17,920 --> 00:06:19,259
可逆壓縮

119
00:06:19,259 --> 00:06:21,620
和非可逆壓縮兩者都支援，

120
00:06:21,620 --> 00:06:22,420
有這樣一點。

121
00:06:22,420 --> 00:06:24,939
以行動 App 的使用情境來說，

122
00:06:24,939 --> 00:06:26,639
大多會把它當作 PNG 的

123
00:06:26,639 --> 00:06:27,540
替代品來用，

124
00:06:27,540 --> 00:06:29,120
我想這種用法很常見，

125
00:06:29,120 --> 00:06:32,939
所以很多人認知是用無損壓縮，會比 PNG 還小，

126
00:06:32,939 --> 00:06:36,639
應該不少人是這樣理解的。

127
00:06:36,639 --> 00:06:41,480
但實際上也能用像 JPEG 那樣的有損壓縮。

128
00:06:41,480 --> 00:06:46,199
而且實務上，有損（lossy）格式

129
00:06:46,199 --> 00:06:48,360
反而用得更多。

130
00:06:48,360 --> 00:06:52,160
在大多數與 WebP 相關的工具裡，

131
00:06:52,160 --> 00:06:54,819
因為這邊的資料量更小，

132
00:06:54,819 --> 00:06:58,800
預設多半都是 lossy 形式。

133
00:06:58,800 --> 00:07:03,639
所以如果你以為用 WebP 就不會有品質劣化，

134
00:07:03,639 --> 00:07:08,339
從工具把 PNG 轉成 WebP 時，其實可能默默就變成 lossy 了，

135
00:07:08,339 --> 00:07:10,040
這裡要特別小心別踩坑。

136
00:07:10,040 --> 00:07:15,420
總結一下，WebP 是為了網頁或 App 的傳輸配信

137
00:07:15,420 --> 00:07:19,180
以盡量降低資料容量為目的所打造，

138
00:07:19,180 --> 00:07:22,680
有 lossy 形式可以用在照片，

139
00:07:22,680 --> 00:07:25,100
用 lossless 的話就很適合插畫或圖示，

140
00:07:25,100 --> 00:07:29,879
基本上能涵蓋幾乎所有類型的影像，

141
00:07:29,879 --> 00:07:33,139
也就是同時有 lossless 和 lossy 兩種壓縮模式，

142
00:07:33,139 --> 00:07:36,899
大概知道到這個程度就差不多了。

143
00:07:36,899 --> 00:07:41,180
接著談談在 iOS 上的支援狀況，

144
00:07:41,180 --> 00:07:44,540
基本上 iOS 14 之後就幾乎都能用了，

145
00:07:44,540 --> 00:07:47,879
應該說幾乎是完整可用。

146
00:07:47,879 --> 00:07:50,779
在 Safari WebView 顯示網頁沒問題，

147
00:07:50,779 --> 00:07:53,319
如果是在原生 App 端操作，

148
00:07:53,319 --> 00:07:55,339
用 CGImageSource 的話，

149
00:07:55,339 --> 00:07:58,579
不論是單張靜態圖或動畫都能讀取。

150
00:07:58,579 --> 00:08:01,180
如果只需要靜態圖，

151
00:08:01,180 --> 00:08:04,740
也可以用 UIImage 的 initializer 直接實例化。

152
00:08:04,740 --> 00:08:07,540
不過編碼（encode）這塊不支援。

153
00:08:07,540 --> 00:08:09,220
PNG 可以輸出，

154
00:08:09,220 --> 00:08:13,279
但在 iOS 或 Mac 上要生成 WebP，標準並不支援。

155
00:08:13,279 --> 00:08:15,439
所以接下來，

156
00:08:15,439 --> 00:08:18,740
我想帶大家看看 WebP 的內部。

157
00:08:18,740 --> 00:08:22,420
先照慣例從資料結構開始看起。

158
00:08:22,420 --> 00:08:26,079
和一般的資料格式一樣，

159
00:08:26,079 --> 00:08:28,399
WebP 也分成 header 和 data。

160
00:08:28,399 --> 00:08:30,100
header 裡放的是資料種類、

161
00:08:30,100 --> 00:08:31,839
大小等這些中繼資料，

162
00:08:31,839 --> 00:08:34,539
而實際影像內容在 data 部分。

163
00:08:34,539 --> 00:08:38,220
在 WebP 裡，header 和 data

164
00:08:38,220 --> 00:08:40,879
並不是 WebP 自創的設計，

165
00:08:40,879 --> 00:08:43,019
而是沿用其他檔案格式也會用到的

166
00:08:43,019 --> 00:08:46,960
RIFF（Resource Interchange File Format）。

167
00:08:46,960 --> 00:08:50,899
RIFF 是一種通用的資料格式，

168
00:08:50,899 --> 00:08:55,620
設計上就像個簡單的容器，可以放任意資料。

169
00:08:55,620 --> 00:09:02,299
所以 RIFF 最上層的結構也會被稱作 RIFF container。

170
00:09:02,299 --> 00:09:09,139
RIFF 的結構是由稱為 chunk 的資料群組組成，

171
00:09:09,139 --> 00:09:13,139
一個 RIFF container 可以包含多個 chunk。

172
00:09:13,139 --> 00:09:20,659
chunk 的結構，開頭會有個表示資料種類的 ID，稱為 FourCC（Four Character Code），

173
00:09:20,659 --> 00:09:24,340
FourCC 是用 4 個英文字母表示，

174
00:09:24,340 --> 00:09:25,200
所以才會這樣稱呼。

175
00:09:25,200 --> 00:09:26,879
就是四個字元碼這樣。

176
00:09:26,879 --> 00:09:32,419
接著是該 chunk 本體資料的大小。

177
00:09:32,419 --> 00:09:34,299
先看第一個 chunk，

178
00:09:34,299 --> 00:09:37,340
如果是 RIFF 檔，這個會表示整個 RIFF container 本身，

179
00:09:37,340 --> 00:09:40,519
這裡一定會是 RIFF，

180
00:09:40,519 --> 00:09:42,340
也就是 RIFF 這個 ID。

181
00:09:42,340 --> 00:09:44,360
不只 WebP，

182
00:09:44,360 --> 00:09:47,259
任何採用這個 RIFF container 的檔案格式，

183
00:09:47,259 --> 00:09:50,519
一開始都會以 RIFF 開頭。

184
00:09:50,519 --> 00:09:53,440
然後會寫入實際資料部分的大小，

185
00:09:53,440 --> 00:09:56,519
比方說如果只有一個 chunk，

186
00:09:56,519 --> 00:09:58,960
整體大小是 100 bytes 的話，

187
00:09:58,960 --> 00:10:01,940
這個 size 會把開頭的 RIFF 與

188
00:10:01,940 --> 00:10:05,100
自身檔案大小欄位的容量排除掉，

189
00:10:05,100 --> 00:10:07,580
也就是會寫入 92 bytes。

190
00:10:07,580 --> 00:10:11,360
以 WebP 檔來說，

191
00:10:11,360 --> 00:10:13,360
這個 RIFF chunk 的 payload

192
00:10:13,360 --> 00:10:16,500
會放表示 WebP 檔的 FourCC ID，

193
00:10:16,500 --> 00:10:19,779
也就是寫上 WEBP 這個名字，

194
00:10:19,779 --> 00:10:21,399
直接作為 ID 放進去。

195
00:10:21,399 --> 00:10:27,679
讀到這裡你就知道，這個檔是 WebP 格式了。

196
00:10:27,679 --> 00:10:33,779
從開頭到 WEBP 為止，這個 FourCC 區塊的 12 bytes

197
00:10:33,779 --> 00:10:35,960
有時也被稱為 WebP header。

198
00:10:35,960 --> 00:10:43,240
接著就要依照 WebP 格式規格來解讀下去，

199
00:10:43,240 --> 00:10:48,940
這樣一來就能知道 WebP 支援哪些功能、

200
00:10:48,940 --> 00:10:50,879
包含影像形式與有什麼功能。

201
00:10:50,879 --> 00:10:51,960
需要加以控制

202
00:10:51,960 --> 00:10:55,000
如剛才提到的，WebP 標準就

203
00:10:55,000 --> 00:10:57,820
支援兩種格式（有損與無損），所以

204
00:10:57,820 --> 00:11:01,259
至少可以知道會有兩種資料進來

205
00:11:01,259 --> 00:11:03,600
如果有用到動畫的話，

206
00:11:03,600 --> 00:11:06,299
就會包含多個影像資料，然後

207
00:11:06,299 --> 00:11:08,659
而在各個圖片的動畫影格中

208
00:11:08,659 --> 00:11:10,779
也可以混用有損和無損

209
00:11:10,779 --> 00:11:13,559
像 Exif 或色彩配置檔這類

210
00:11:13,559 --> 00:11:16,559
也支援保留這些中繼資料

211
00:11:16,559 --> 00:11:20,639
比方說，裡面是有損格式的靜態圖時，

212
00:11:20,639 --> 00:11:24,940
接著該 chunk header 會是 VP8 後面一個空白字元

213
00:11:24,940 --> 00:11:28,240
4CC 是規定用四個英文字母，所以

214
00:11:28,240 --> 00:11:30,659
因此最後一定會有一個空白

215
00:11:30,659 --> 00:11:31,940
三個字是不行的

216
00:11:31,940 --> 00:11:35,320
「VP8 」含空白才是正式的 4CC

217
00:11:35,320 --> 00:11:40,419
無損格式的 4CC 則是 VP8L

218
00:11:40,419 --> 00:11:45,460
chunk 大小就是用總長度減掉這個區塊的標頭大小

219
00:11:45,460 --> 00:11:48,159
這種情況就是有 80 個位元組

220
00:11:48,159 --> 00:11:50,059
接著在後面的 chunk payload 裡，

221
00:11:50,059 --> 00:11:52,240
就會放入壓縮後的影像資料本體

222
00:11:52,240 --> 00:11:54,899
這種只有一個這樣的 chunk 的

223
00:11:54,899 --> 00:11:56,320
WebP 格式，

224
00:11:56,320 --> 00:11:59,440
在 WebP 裡稱為 Simple File Format

225
00:11:59,440 --> 00:12:02,019
有損和無損

226
00:12:02,019 --> 00:12:05,240
壓縮方式和各種處理都完全不同，

227
00:12:05,240 --> 00:12:06,960
幾乎沒有共通部分，

228
00:12:06,960 --> 00:12:08,159
所以不能用同一套處理，

229
00:12:08,159 --> 00:12:09,799
在解碼器的實作裡，

230
00:12:09,799 --> 00:12:11,279
會先看 chunk header，

231
00:12:11,279 --> 00:12:14,679
然後把處理完全分成兩條路的實作

232
00:12:14,679 --> 00:12:19,679
WebP 難實作的另一個理由是，

233
00:12:19,679 --> 00:12:21,299
如果要把全部功能都實作出來，

234
00:12:21,299 --> 00:12:23,240
在有損和無損這兩邊，

235
00:12:23,240 --> 00:12:24,340
已經是完全不同的，

236
00:12:24,340 --> 00:12:28,200
基本上就像在寫兩套不同的軟體，

237
00:12:28,200 --> 00:12:31,740
這點也就相當辛苦

238
00:12:31,740 --> 00:12:35,179
要包含 Exif 中繼資料，

239
00:12:35,179 --> 00:12:36,299
或是要用動畫的話，

240
00:12:36,299 --> 00:12:38,759
就塞不進 Simple File Format，

241
00:12:38,759 --> 00:12:41,379
需要用 Extended File Format

242
00:12:41,379 --> 00:12:43,600
在 Extended File Format 裡，

243
00:12:43,600 --> 00:12:49,440
會放置一個 4CC 為 VP8X、長度固定 10 bytes 的 chunk，

244
00:12:49,440 --> 00:12:55,100
一看到它，就知道後面還會跟著中繼資料或動畫相關的資訊

245
00:12:55,100 --> 00:12:59,419
這個 VP8X 會標示出有哪些功能被啟用，

246
00:12:59,419 --> 00:13:01,860
那些旗標就塞在這 10 個位元組裡

247
00:13:01,860 --> 00:13:07,539
當某個旗標為啟用時，通常就會有對應的資料以 chunk 的形式出現

248
00:13:07,539 --> 00:13:12,440
像 Exif 這種不影響渲染的，放哪裡都可以，

249
00:13:12,440 --> 00:13:15,500
但像色彩配置檔、動畫、Alpha 這些，

250
00:13:15,500 --> 00:13:20,120
基本上要照順序放在前面，

251
00:13:20,120 --> 00:13:23,960
有必須出現在影像資料之前的規則

252
00:13:23,960 --> 00:13:30,120
比方說，旗標沒有把動畫功能打開，

253
00:13:30,120 --> 00:13:31,620
卻出現了動畫的 chunk，

254
00:13:31,620 --> 00:13:37,659
或是混進一些完全無關 ID 的 chunk，

255
00:13:37,659 --> 00:13:39,899
基本上都會被忽略

256
00:13:39,899 --> 00:13:42,919
這類會被當作 Unknown chunk 來處理，

257
00:13:42,919 --> 00:13:45,200
原則上不會當成錯誤

258
00:13:45,200 --> 00:13:50,820
利用這點，也可以把任意資料塞進檔案裡，

259
00:13:50,820 --> 00:13:52,500
理論上是可行的

260
00:13:52,500 --> 00:13:54,600
總之呢，

261
00:13:54,600 --> 00:13:59,080
作為第一步，先來試試讀取資料以外的標頭部分

262
00:13:59,080 --> 00:14:04,419
如同剛才看到的，影像資料以外的資訊

263
00:14:04,419 --> 00:14:07,639
是採用 RIFF 格式的結構，

264
00:14:07,639 --> 00:14:09,639
會有 4 位元組的 4CC，

265
00:14:09,639 --> 00:14:11,080
接著是 4 位元組的大小欄位，

266
00:14:11,080 --> 00:14:13,740
然後才是 chunk data，

267
00:14:13,740 --> 00:14:16,779
於是就依讀到的大小把資料跳過，

268
00:14:16,779 --> 00:14:18,120
如果後面還有資料，

269
00:14:18,120 --> 00:14:20,659
再以同樣方式讀 4 位元組的 4CC，

270
00:14:20,659 --> 00:14:22,200
按順序讀下去就可以了

271
00:14:22,200 --> 00:14:24,159
也就是說，所謂讀標頭就是

272
00:14:24,159 --> 00:14:25,799
把影像資料的部分跳過，

273
00:14:25,799 --> 00:14:27,139
只讀標頭的感覺

274
00:14:27,139 --> 00:14:28,940
如果只是讀這些的話，

275
00:14:28,940 --> 00:14:30,179
裡面就是原始位元組，

276
00:14:30,179 --> 00:14:32,100
不需要解壓縮處理，

277
00:14:32,100 --> 00:14:33,080
非常簡單，

278
00:14:33,080 --> 00:14:34,360
不過光是這樣，

279
00:14:34,360 --> 00:14:37,059
WebP 檔是有損還是無損、

280
00:14:37,059 --> 00:14:38,200
有沒有包含動畫，

281
00:14:38,200 --> 00:14:40,620
都能拿得到這些資訊

282
00:14:40,620 --> 00:14:43,539
RIFF 標頭 reader 呢，

283
00:14:43,539 --> 00:14:44,840
大概會長這樣，

284
00:14:44,840 --> 00:14:46,399
是這個樣子

285
00:14:46,399 --> 00:14:48,559
這個是 RIFF Header Reader

286
00:14:48,559 --> 00:14:49,460
這個名字，

287
00:14:49,460 --> 00:14:50,960
有放在範例程式裡，

288
00:14:50,960 --> 00:14:52,980
用這個，

289
00:14:52,980 --> 00:14:55,379
如果平常不太寫二進位操作的話，

290
00:14:55,379 --> 00:14:57,899
可以先當作入門來玩玩，

291
00:14:57,899 --> 00:15:00,240
多讀幾個各種 WebP 檔看看，

292
00:15:00,240 --> 00:15:02,500
有種「喔原來如此」的感覺，

293
00:15:02,500 --> 00:15:04,500
應該也會蠻有趣的

294
00:15:04,500 --> 00:15:09,679
接下來就要正式來看影像資料的內容了

295
00:15:09,679 --> 00:15:12,360
就像一開始說的，

296
00:15:12,360 --> 00:15:17,779
WebP 的影像資料不是在什麼都不了解的情況下就能直接讀的，

297
00:15:17,779 --> 00:15:18,840
並不是那樣

298
00:15:18,840 --> 00:15:21,539
它經過了多個階段的壓縮與轉換，

299
00:15:21,539 --> 00:15:26,200
幾乎沒有能直接讀的原始位元資料

300
00:15:26,200 --> 00:15:29,460
所以先從其中一種處理開始

301
00:15:29,460 --> 00:15:32,980
我會自己做只加了轉換處理的 WebP 圖片

302
00:15:32,980 --> 00:15:36,419
為什麼要自己做呢

303
00:15:36,419 --> 00:15:38,139
一方面是為了理解

304
00:15:38,139 --> 00:15:39,399
但那種資料在世上

305
00:15:39,399 --> 00:15:40,980
基本上沒有那種 WebP 檔案

306
00:15:40,980 --> 00:15:44,120
在 libwebp 的測試資料裡

307
00:15:44,120 --> 00:15:46,980
為了確認那類處理

308
00:15:46,980 --> 00:15:50,019
像是只套了這種轉換的

309
00:15:50,019 --> 00:15:51,620
測試資料也有，不過

310
00:15:51,620 --> 00:15:53,759
就算要把它解碼

311
00:15:53,759 --> 00:15:55,179
還是需要相當一點的實作

312
00:15:55,179 --> 00:15:57,419
但真正極簡的測試資料是沒有的

313
00:15:57,419 --> 00:15:59,700
所以只好自己做

314
00:15:59,700 --> 00:16:02,559
要做成什麼樣的資料呢

315
00:16:02,559 --> 00:16:04,779
從規格來想的話

316
00:16:04,779 --> 00:16:07,779
有損或無損

317
00:16:07,779 --> 00:16:09,639
另外如果是動畫的話

318
00:16:09,639 --> 00:16:12,220
會包含多個有損或無損的資料

319
00:16:12,220 --> 00:16:13,600
大概是這樣

320
00:16:13,600 --> 00:16:18,179
首先，中繼資料這次和壓縮/解碼無關

321
00:16:18,179 --> 00:16:20,000
先不納入範圍

322
00:16:20,000 --> 00:16:23,179
動畫的話，每個影格

323
00:16:23,179 --> 00:16:25,100
基本上跟靜態圖是一樣的

324
00:16:25,100 --> 00:16:26,960
這次也先不談

325
00:16:26,960 --> 00:16:30,480
不過動畫會把背景拆出來之類的

326
00:16:30,480 --> 00:16:35,059
只寫入變動的部分之類的

327
00:16:35,059 --> 00:16:39,039
有那種只寫差分的動畫特有機制

328
00:16:39,039 --> 00:16:43,559
所以要完整支援動畫的話，還是需要額外的實作

329
00:16:43,559 --> 00:16:47,299
所以在範例程式碼裡

330
00:16:47,299 --> 00:16:50,960
針對含 α 的有損與無損格式

331
00:16:50,960 --> 00:16:53,700
最終都有支援解碼

332
00:16:53,700 --> 00:16:56,980
無損裡面永遠都有 α

333
00:16:56,980 --> 00:16:59,720
支援 Simple File Format

334
00:16:59,720 --> 00:17:02,340
另外 Extended File Format 則可以讀到 α

335
00:17:02,340 --> 00:17:07,559
這段時間就來講無損格式

336
00:17:07,559 --> 00:17:11,920
相較於有損，無損各步驟都比較單純

337
00:17:11,920 --> 00:17:13,279
應該也比較好懂

338
00:17:13,279 --> 00:17:18,200
關於資料的轉換，也比較容易看出輸入是什麼

339
00:17:18,200 --> 00:17:20,740
只要有這種最小化的資料

340
00:17:20,740 --> 00:17:23,839
其實就能一步步推進，不會太難

341
00:17:23,839 --> 00:17:29,000
那我們來看 VP8L 的資料結構

342
00:17:29,000 --> 00:17:33,839
一般來說 WebP 的資料部分稱為 bitstream

343
00:17:33,839 --> 00:17:37,859
bitstream 的開頭有 VP8L 的 header

344
00:17:37,859 --> 00:17:42,140
裡面有固定值

345
00:17:42,140 --> 00:17:45,559
接著是寬和高

346
00:17:45,559 --> 00:17:47,880
然後會有關於是否有 alpha、以及版本的欄位

347
00:17:47,880 --> 00:17:52,039
以 VP8L 的無損資料來說

348
00:17:52,039 --> 00:17:53,539
alpha 一定會在資料裡

349
00:17:53,539 --> 00:17:55,880
這個讀不讀都沒差

350
00:17:55,880 --> 00:18:00,559
所以基本上只需要寬高這兩個資訊

351
00:18:00,559 --> 00:18:03,039
版本值現在也都是 0，

352
00:18:03,039 --> 00:18:04,519
就是 0

353
00:18:04,519 --> 00:18:05,880
可以直接跳過沒關係，不過

354
00:18:05,880 --> 00:18:07,880
基本上如果來了不同的值

355
00:18:07,880 --> 00:18:09,660
就代表資料不合法

356
00:18:09,660 --> 00:18:11,500
通常會當成錯誤

357
00:18:11,500 --> 00:18:14,960
顧名思義是 bitstream

358
00:18:14,960 --> 00:18:17,240
這些資料必須以 bit 為單位來讀

359
00:18:17,240 --> 00:18:21,559
像寬高本來就會跨越 byte 邊界

360
00:18:21,559 --> 00:18:25,579
因為這個格式傾向於連 1 個 bit 都要省下來

361
00:18:25,579 --> 00:18:29,539
所以會盡量以 bit 單位緊密地寫入

362
00:18:29,539 --> 00:18:35,079
大多數程式語言並沒有直接按 bit 讀取的功能

363
00:18:35,079 --> 00:18:36,759
這部分得自己實作

364
00:18:36,759 --> 00:18:41,140
做法就是把以 byte 讀進來的資料

365
00:18:41,140 --> 00:18:43,819
用 bit shift 取出需要的位元

366
00:18:43,819 --> 00:18:46,759
不夠的話就再讀 1 個 byte

367
00:18:46,759 --> 00:18:51,039
Header 的資料是可以直接讀的原始 bit

368
00:18:51,039 --> 00:18:54,140
只要先做出讀 bit 的這類處理

369
00:18:54,140 --> 00:18:55,359
就能把標頭那段讀出來

370
00:18:55,359 --> 00:18:57,640
這樣能知道什麼呢？

371
00:18:57,640 --> 00:19:00,059
就是影像的寬高尺寸

372
00:19:00,059 --> 00:19:03,299
寬高這件事

373
00:19:03,299 --> 00:19:06,259
在做影像處理時非常重要

374
00:19:06,259 --> 00:19:08,200
因為影像資料

375
00:19:08,200 --> 00:19:10,200
我們肉眼看是個矩形

376
00:19:10,200 --> 00:19:11,680
可是在軟體裡

377
00:19:11,680 --> 00:19:15,440
它其實是記憶體裡一段連續的一維陣列

378
00:19:15,440 --> 00:19:19,980
而影像壓縮的方法

379
00:19:19,980 --> 00:19:23,019
常常會利用鄰近像素顏色相近

380
00:19:23,019 --> 00:19:27,460
這類的假設

381
00:19:27,460 --> 00:19:28,700
在那種情況下

382
00:19:28,700 --> 00:19:30,460
記憶體上相鄰

383
00:19:30,460 --> 00:19:33,259
實際畫面上可能是左右邊界兩端

384
00:19:33,259 --> 00:19:36,339
反過來，記憶體上相隔很遠

385
00:19:36,339 --> 00:19:40,640
畫面上卻可能是上下相鄰

386
00:19:40,640 --> 00:19:43,980
所以寬高非常重要

387
00:19:43,980 --> 00:19:45,119
大多數格式

388
00:19:45,119 --> 00:19:47,559
都會在讀到實際像素之前就讓你知道

389
00:19:47,559 --> 00:19:49,460
因此通常會放在檔頭前段

390
00:19:49,460 --> 00:19:51,599
也有少數放比較後面的格式啦

391
00:19:51,599 --> 00:19:56,140
Header 後面就是壓縮過的影像資料

392
00:19:56,140 --> 00:19:58,579
那可就不是單純的原始 bit 了

393
00:19:58,579 --> 00:20:00,420
不做點處理是讀不出來的

394
00:20:00,420 --> 00:20:03,859
以無損資料的壓縮流程來說

395
00:20:03,859 --> 00:20:05,019
大概是像這樣

396
00:20:05,019 --> 00:20:08,680
大概會經過 3 到 6 種步驟，也許更多

397
00:20:08,680 --> 00:20:11,119
一路處理完才會生成

398
00:20:11,119 --> 00:20:14,039
這就是門檻所在

399
00:20:14,039 --> 00:20:15,799
關於各步驟的概念

400
00:20:15,799 --> 00:20:17,980
在規格書裡幾乎沒寫

401
00:20:17,980 --> 00:20:19,319
雖然有把步驟寫出來了

402
00:20:19,319 --> 00:20:20,539
但沒說這到底是什麼

403
00:20:20,539 --> 00:20:25,039
不懂這個的話，基本上就不知道這在做什麼

404
00:20:25,039 --> 00:20:28,059
還原則是把它反過來做

405
00:20:28,059 --> 00:20:31,240
不管怎樣，不懂的話兩邊都寫不出來

406
00:20:31,240 --> 00:20:34,460
所以就需要對流程有一定的認識

407
00:20:34,460 --> 00:20:41,920
最後我們還是想一個一個把它搞懂

408
00:20:41,920 --> 00:20:44,420
但照一般方式做其實很難

409
00:20:44,420 --> 00:20:48,980
在這裡先準備一個只實作其中一步的編解碼器（codec），以及

410
00:20:48,980 --> 00:20:50,519
對應的資料

411
00:20:50,519 --> 00:20:53,500
這樣就能先做第一步的驗證

412
00:20:53,500 --> 00:20:57,339
之後就可以持續往下接著做，採這種漸進式的做法

413
00:20:57,339 --> 00:21:00,720
這個我有當作範例程式公開

414
00:21:00,720 --> 00:21:02,339
就是剛剛提到的那個套件

415
00:21:02,339 --> 00:21:04,420
裡面每一個對應到哪個步驟

416
00:21:04,420 --> 00:21:06,160
基本上有命名的那些

417
00:21:06,160 --> 00:21:09,920
就對應到同名的壓縮流程

418
00:21:09,920 --> 00:21:14,640
這個 BitStream 最後會

419
00:21:14,640 --> 00:21:16,380
被所謂的前綴編碼（prefix coding）

420
00:21:16,380 --> 00:21:18,900
這種壓縮手法改寫

421
00:21:18,900 --> 00:21:22,180
所以前綴編碼這一步是一定會經過的

422
00:21:22,180 --> 00:21:28,059
除此之外，基本上每個套件都只做一件事

423
00:21:28,059 --> 00:21:30,099
也就是各自只實作其中一項

424
00:21:30,099 --> 00:21:36,299
第8個那個則是完整功能的解碼器／編碼器

425
00:21:36,299 --> 00:21:39,700
總之，照我們剛才看到的

426
00:21:39,700 --> 00:21:42,940
必要的步驟其實就是前綴編碼

427
00:21:42,940 --> 00:21:45,599
所以先從實作前綴編碼開始

428
00:21:45,599 --> 00:21:48,640
世界上不會有只做了前綴編碼、

429
00:21:48,640 --> 00:21:50,759
就拿來當 WebP 圖片的東西

430
00:21:50,759 --> 00:21:53,759
但一開始把這個做出來

431
00:21:53,759 --> 00:21:55,220
才是最根本的基礎

432
00:21:55,220 --> 00:21:58,180
與其說是前綴編碼

433
00:21:58,180 --> 00:21:59,420
大概大家更熟的是哈夫曼編碼

434
00:21:59,420 --> 00:22:00,799
或是哈夫曼解碼這種講法

435
00:22:00,799 --> 00:22:02,339
會比較耳熟

436
00:22:02,339 --> 00:22:05,680
不過在 WebP 的規格書裡

437
00:22:05,680 --> 00:22:08,259
「哈夫曼解碼」這個詞完全沒有出現

438
00:22:08,259 --> 00:22:10,299
全都寫成前綴編碼

439
00:22:10,299 --> 00:22:13,299
嚴格區分術語的話，大概是這樣

440
00:22:13,299 --> 00:22:14,519
在前綴編碼這個大類裡

441
00:22:14,519 --> 00:22:16,619
哈夫曼編碼只是其中一種

442
00:22:16,619 --> 00:22:17,740
大概是這個概念

443
00:22:17,740 --> 00:22:21,420
而在 WebP 裡，哈夫曼編碼一律是

444
00:22:21,420 --> 00:22:22,920
規範哈夫曼編碼（canonical Huffman coding）

445
00:22:22,920 --> 00:22:26,259
這些統稱為前綴編碼

446
00:22:26,259 --> 00:22:31,059
所以在這場演講裡提到哈夫曼編碼

447
00:22:31,059 --> 00:22:33,799
都是指規範哈夫曼編碼

448
00:22:33,799 --> 00:22:35,099
先在這邊統一下說法

449
00:22:35,099 --> 00:22:40,019
先從一般的哈夫曼法講起

450
00:22:40,019 --> 00:22:44,079
所謂壓縮是在做什麼呢

451
00:22:44,079 --> 00:22:45,759
就是把資料裡的冗餘

452
00:22:45,759 --> 00:22:48,180
換成較短的表達

453
00:22:48,180 --> 00:22:50,000
冗餘有很多種

454
00:22:50,000 --> 00:22:51,640
在哈夫曼編碼裡

455
00:22:51,640 --> 00:22:54,180
利用統計上的偏差

456
00:22:54,180 --> 00:22:55,460
也就是常出現的值

457
00:22:55,460 --> 00:22:57,440
和不常出現的值之間的

458
00:22:57,440 --> 00:22:58,700
出現偏差

459
00:22:58,700 --> 00:23:01,180
對於常出現的值

460
00:23:01,180 --> 00:23:03,299
也就是高頻的符號

461
00:23:03,299 --> 00:23:05,200
分配較短的碼

462
00:23:05,200 --> 00:23:06,740
對於出現頻率低的

463
00:23:06,740 --> 00:23:09,960
符號就分配較長的碼

464
00:23:09,960 --> 00:23:11,359
這就是哈夫曼編碼

465
00:23:11,359 --> 00:23:13,839
在直接拿影像資料

466
00:23:13,839 --> 00:23:15,660
來做編碼之前

467
00:23:15,660 --> 00:23:18,519
先用一個簡單的字串當例子

468
00:23:18,519 --> 00:23:19,980
以「bookkeeper」這個單字

469
00:23:19,980 --> 00:23:22,319
來做哈夫曼編碼的話

470
00:23:22,319 --> 00:23:25,420
第一步先統計各字母的出現頻率

471
00:23:25,420 --> 00:23:26,599
E 出現 3 次

472
00:23:26,599 --> 00:23:27,440
O 和 K 各 2 次

473
00:23:27,440 --> 00:23:29,319
B、P、R 各 1 次

474
00:23:29,319 --> 00:23:32,220
把它整理成表，按頻率排序

475
00:23:32,220 --> 00:23:33,759
左邊的是高頻

476
00:23:33,759 --> 00:23:35,119
因為有偏差

477
00:23:35,119 --> 00:23:38,619
也就是存在冗餘，所以能被壓縮

478
00:23:38,619 --> 00:23:41,200
越常出現的字用越短的碼

479
00:23:41,200 --> 00:23:44,019
不常出現的字就用較長的碼來表示

480
00:23:44,019 --> 00:23:46,140
步驟如下

481
00:23:46,140 --> 00:23:48,960
與其念步驟，直接看比較快

482
00:23:48,960 --> 00:23:51,160
我們直接來看

483
00:23:51,160 --> 00:23:54,660
先從頻率表直接

484
00:23:54,660 --> 00:23:57,619
建立葉節點（leaf）

485
00:23:57,619 --> 00:23:59,720
就是把它抄過來而已

486
00:23:59,720 --> 00:24:03,279
取出頻率最低的兩個符號

487
00:24:03,279 --> 00:24:05,240
組成一個二叉分支

488
00:24:05,240 --> 00:24:06,299
不斷重複這個動作

489
00:24:06,299 --> 00:24:10,339
父節點的頻率等於葉節點頻率的總和

490
00:24:10,339 --> 00:24:14,480
父節點也會成為後續可合併的對象

491
00:24:14,480 --> 00:24:20,759
同樣地，取出剩下的兩個再建樹

492
00:24:20,759 --> 00:24:22,839
接著再重複同樣的處理

493
00:24:22,839 --> 00:24:26,259
這裡因為比起 3，父節點的 2 較低

494
00:24:26,259 --> 00:24:29,619
所以 O 的 2 和那個父節點的 2 會成為合併對象

495
00:24:29,619 --> 00:24:31,920
這樣就合併起來

496
00:24:31,920 --> 00:24:37,740
之後就同樣重複，直到只剩一棵樹

497
00:24:37,740 --> 00:24:39,900
持續重複到變成一棵樹

498
00:24:39,900 --> 00:24:42,500
這樣就能得到一棵樹

499
00:24:42,500 --> 00:24:47,259
最初這棵樹長這樣

500
00:24:47,259 --> 00:24:50,799
這就叫作哈夫曼樹（Huffman tree）

501
00:24:50,799 --> 00:24:53,539
做好霍夫曼樹之後

502
00:24:53,539 --> 00:24:56,279
在左邊的分支給 0，右邊的分支給 1

503
00:24:56,279 --> 00:24:57,180
反過來也可以啦

504
00:24:57,180 --> 00:25:00,859
就是把左邊設 0、右邊的分支設 1 這樣分配

505
00:25:00,859 --> 00:25:03,779
然後從根一路走下去就能得到碼

506
00:25:03,779 --> 00:25:08,140
比方說 E 是左、左，所以是 00 這個碼

507
00:25:08,140 --> 00:25:11,980
O 是右、左，所以是 10

508
00:25:11,980 --> 00:25:16,380
K 是左、右、左，所以會是 010 這個碼

509
00:25:16,380 --> 00:25:18,480
這樣碼就確定了

510
00:25:18,480 --> 00:25:22,259
出現頻率高的會得到較短的碼

511
00:25:22,259 --> 00:25:23,279
大概就是這樣

512
00:25:23,279 --> 00:25:26,579
用這些碼把 bookkeeper 這個字串替換掉

513
00:25:26,579 --> 00:25:29,720
就可以像這樣表示，變成 25 位元

514
00:25:29,720 --> 00:25:33,279
假設字符集是從 A 到 Z

515
00:25:33,279 --> 00:25:35,859
表示 1 個字需要 5 位元

516
00:25:35,859 --> 00:25:38,380
原本 5×10 個字等於需要 50 位元的

517
00:25:38,380 --> 00:25:39,380
變成了 25 位元

518
00:25:39,380 --> 00:25:40,819
也就是壓縮了 50%

519
00:25:40,819 --> 00:25:42,660
原理就是這樣

520
00:25:42,660 --> 00:25:46,579
可能有些人剛剛也注意到了

521
00:25:46,579 --> 00:25:48,700
在一般的霍夫曼編碼裡

522
00:25:48,700 --> 00:25:50,960
碼的分配是有自由度的

523
00:25:50,960 --> 00:25:53,039
以剛剛的例子來說

524
00:25:53,039 --> 00:25:56,420
出現頻率相同的 RBP 的碼分配

525
00:25:56,420 --> 00:25:58,200
就算對調也不會改變壓縮率

526
00:25:58,200 --> 00:26:00,319
所以換來換去都可以

527
00:26:00,319 --> 00:26:03,180
不過因為碼的分配不一樣

528
00:26:03,180 --> 00:26:04,519
編碼結果就會不同

529
00:26:04,519 --> 00:26:07,839
因此要把編碼後的結果解碼

530
00:26:07,839 --> 00:26:10,460
就需要那張映射表，也就是碼表

531
00:26:10,460 --> 00:26:13,839
就算把碼表一起傳

532
00:26:13,839 --> 00:26:15,859
只要要壓縮的資料夠大

533
00:26:15,859 --> 00:26:17,440
還是會有壓縮效果

534
00:26:17,440 --> 00:26:21,220
但如果規則是事先固定的

535
00:26:21,220 --> 00:26:24,880
就不需要送碼表了

536
00:26:24,880 --> 00:26:27,900
要做的就是把這種規則定下來

537
00:26:27,900 --> 00:26:29,480
這就是規範霍夫曼編碼

538
00:26:29,480 --> 00:26:32,480
也稱為正準霍夫曼編碼

539
00:26:32,480 --> 00:26:36,420
規範霍夫曼的規則是這樣

540
00:26:36,420 --> 00:26:40,200
看例子最快，我們來試試看

541
00:26:40,200 --> 00:26:48,359
重點是：對於相同長度的碼，先把符號排序，然後依序賦予連號

542
00:26:48,359 --> 00:26:51,599
從樹的根往下走會得到碼

543
00:26:51,599 --> 00:26:54,440
所以碼長就是樹的深度

544
00:26:54,440 --> 00:26:59,880
把同一深度的符號按字典序重新排列

545
00:26:59,880 --> 00:27:06,940
然後對每一組相同長度的，賦予連續的碼值

546
00:27:06,940 --> 00:27:08,039
規則就是這樣

547
00:27:08,039 --> 00:27:10,599
規範霍夫曼就是用這套規則來指定碼

548
00:27:10,599 --> 00:27:13,460
因此不需要共享樹或碼表

549
00:27:13,460 --> 00:27:14,920
解碼所需的

550
00:27:14,920 --> 00:27:19,579
只要把依符號順序排列的碼長傳過去就行

551
00:27:19,579 --> 00:27:23,799
這整套就是規範霍夫曼編碼的機制

552
00:27:23,799 --> 00:27:27,220
所以要解碼的話

553
00:27:27,220 --> 00:27:31,440
就是傳一個按照符號順序排好的碼長序列

554
00:27:31,440 --> 00:27:38,680
因為符號的順序是既知的，所以只要碼長即可

555
00:27:38,680 --> 00:27:43,880
如果不是規範霍夫曼，要傳遞這種霍夫曼編碼

556
00:27:43,880 --> 00:27:47,039
就得把樹的形狀和葉子傳過去

557
00:27:47,039 --> 00:27:51,380
乍看之下，規範霍夫曼好像會多送資料

558
00:27:51,380 --> 00:27:56,359
當使用的符號變多時成本會反轉

559
00:27:56,359 --> 00:27:58,660
但重點不在這裡

560
00:27:58,660 --> 00:28:01,859
規範霍夫曼編碼厲害的地方在於

561
00:28:01,859 --> 00:28:03,640
看這個碼長序列

562
00:28:03,640 --> 00:28:06,220
大部分項目都是 0

563
00:28:06,220 --> 00:28:07,599
其他不是 0 的部分

564
00:28:07,599 --> 00:28:09,500
這個例子很容易看懂

565
00:28:09,500 --> 00:28:12,059
也只有 2 和 3 而已

566
00:28:12,059 --> 00:28:13,680
只需要傳碼長這件事

567
00:28:13,680 --> 00:28:16,119
等於把資料轉成了有利於霍夫曼編碼的形式

568
00:28:16,119 --> 00:28:18,359
也就是完成了這樣的轉換

569
00:28:18,359 --> 00:28:19,799
實際上在 WebP 裡

570
00:28:19,799 --> 00:28:23,599
還會把這個碼長再用霍夫曼編碼壓縮一次

571
00:28:23,599 --> 00:28:28,900
WebP 編碼裡用到的碼長最多也就 15

572
00:28:28,900 --> 00:28:32,200
跟像素取值的變化相比小很多

573
00:28:32,200 --> 00:28:35,240
分布會緊密集中在較小的數字

574
00:28:35,240 --> 00:28:38,299
而且未使用的 0 也會大量出現

575
00:28:38,299 --> 00:28:40,819
因此壓縮效果非常好

576
00:28:40,819 --> 00:28:43,500
我們想要做出這樣的資料

577
00:28:43,500 --> 00:28:47,220
這幾乎就是規範霍夫曼編碼的真正目的

578
00:28:47,220 --> 00:28:50,259
不是規範霍夫曼的

579
00:28:50,259 --> 00:28:52,440
總結一下霍夫曼編碼

580
00:28:52,440 --> 00:28:55,279
它是利用出現頻率偏差來壓縮

581
00:28:55,279 --> 00:28:58,500
在 WebP 中用的是規範霍夫曼編碼

582
00:28:58,500 --> 00:29:00,940
所謂規範霍夫曼編碼

583
00:29:00,940 --> 00:29:03,980
是一種只要知道碼長就能解碼的方式

584
00:29:03,980 --> 00:29:06,500
而這個碼長序列

585
00:29:06,500 --> 00:29:08,759
非常適合再用霍夫曼編碼來壓縮

586
00:29:08,759 --> 00:29:13,000
所以在 WebP 裡，碼長序列也會再做霍夫曼編碼

587
00:29:13,000 --> 00:29:14,839
算是多段，會出現兩次

588
00:29:14,839 --> 00:29:18,940
這既是難點之一

589
00:29:18,940 --> 00:29:21,079
也是關鍵所在

590
00:29:21,079 --> 00:29:26,819
從微觀角度看，會對相似的資料套用多次霍夫曼編碼

591
00:29:26,819 --> 00:29:29,380
就會有點搞不清楚現在在做什麼

592
00:29:29,380 --> 00:29:32,279
真的在寫的時候很容易迷路

593
00:29:32,279 --> 00:29:32,980
這是其一

594
00:29:32,980 --> 00:29:36,500
另外從宏觀來看，這個 WebP 的流程

595
00:29:36,500 --> 00:29:39,839
反正最後一定會套用霍夫曼編碼

596
00:29:39,839 --> 00:29:44,420
為了把霍夫曼編碼的效果發揮到最大

597
00:29:44,420 --> 00:29:49,299
你甚至可以把 WebP 的處理都看作是在為霍夫曼編碼鋪路

598
00:29:49,299 --> 00:29:50,779
這樣理解也不算錯

599
00:29:50,779 --> 00:29:55,220
既然最後會套用霍夫曼編碼

600
00:29:55,220 --> 00:29:57,359
那在此之前，就在可復原的範圍內

601
00:29:57,359 --> 00:30:02,079
這就是 VP 在做的事：讓資料變成最有利於 Huffman 編碼的形態

602
00:30:02,079 --> 00:30:04,039
理解了這點之後

603
00:30:04,039 --> 00:30:09,240
就會慢慢看懂 VP 那些複雜的機制和處理流程

604
00:30:09,240 --> 00:30:14,380
把實際的圖片拿來做 Huffman 編碼會怎麼樣呢

605
00:30:14,380 --> 00:30:17,240
這有點靠直覺啦

606
00:30:17,240 --> 00:30:21,859
在 VP8L 裡面，內部是用圖片的 RGBA 四個通道

607
00:30:21,859 --> 00:30:26,259
會對每個成分分別做 Huffman 編碼

608
00:30:26,259 --> 00:30:31,400
所謂出現次數，就是指 RGBA 各成分的出現頻率

609
00:30:31,400 --> 00:30:35,119
例如只看綠色成分

610
00:30:35,119 --> 00:30:40,920
出現的數值大概長這樣、頻率分布大概是這樣

611
00:30:40,920 --> 00:30:45,460
把特別常見的 206 設成比較短的符號

612
00:30:45,460 --> 00:30:46,019
也就是用短碼來表示

613
00:30:46,019 --> 00:30:49,380
而 0、66、100 這些就用比較長的碼

614
00:30:49,380 --> 00:30:51,400
這樣去編碼的就是 Huffman 編碼

615
00:30:51,400 --> 00:30:55,140
在沒有做任何前處理

616
00:30:55,140 --> 00:30:56,740
只是單純的一張圖片

617
00:30:56,740 --> 00:30:58,740
就算只做 Huffman 編碼

618
00:30:58,740 --> 00:31:00,480
看這個就會發現

619
00:31:00,480 --> 00:31:01,240
一旦按成分拆開

620
00:31:01,240 --> 00:31:02,759
有不少幾乎沒被用到的符號

621
00:31:02,759 --> 00:31:04,460
分布其實很偏

622
00:31:04,460 --> 00:31:07,559
正因為這樣，就能壓得非常小

623
00:31:07,559 --> 00:31:08,900
編碼後會變成這樣

624
00:31:08,900 --> 00:31:11,079
像 206 幾乎只要用 0 就能

625
00:31:11,079 --> 00:31:12,819
把它表達出來

626
00:31:12,819 --> 00:31:14,559
體積就會大幅下降

627
00:31:14,559 --> 00:31:18,119
這是實際圖片的大小

628
00:31:18,119 --> 00:31:21,420
這張是 16×16，所以本來就很小

629
00:31:21,420 --> 00:31:25,700
跟真實場景的圖片還是有不小差異

630
00:31:25,700 --> 00:31:29,880
即便如此，不壓縮也有 1302 bytes

631
00:31:29,880 --> 00:31:33,759
光套個簡單的 Huffman 就能縮到 384 bytes

632
00:31:33,759 --> 00:31:39,839
實際上我們還會做一些轉換，讓它更好壓

633
00:31:39,839 --> 00:31:42,240
就算只看剛剛那個 Green

634
00:31:42,240 --> 00:31:45,700
雖然只靠 Green 也已經能壓得很緊

635
00:31:45,700 --> 00:31:48,980
但這樣做會讓壓縮更上一層樓

636
00:31:48,980 --> 00:31:52,460
先把 Huffman 編碼再整理一下

637
00:31:52,460 --> 00:31:59,319
在真實圖片的資料裡，有些符號會大量出現

638
00:31:59,319 --> 00:32:04,240
而且按成分、特別是按 RGB 分開看的話，分布偏得很明顯

639
00:32:04,240 --> 00:32:06,400
所以 Huffman 編碼會非常有效

640
00:32:06,400 --> 00:32:10,980
另外在 WebP 裡，為了進一步強化 Huffman 編碼的效果

641
00:32:10,980 --> 00:32:14,140
會在前處理階段套用各種轉換，這就是 WebP 的作法

642
00:32:14,140 --> 00:32:18,440
其中只有 Huffman 編碼是必須步驟

643
00:32:18,440 --> 00:32:19,980
沒做 Huffman 編碼的資料

644
00:32:19,980 --> 00:32:23,920
就不會被當成 WebP

645
00:32:23,920 --> 00:32:26,099
所以，也正因為這樣

646
00:32:26,099 --> 00:32:28,259
只要先把 Huffman 編碼做好

647
00:32:28,259 --> 00:32:30,880
作為規格上就算是正確的 WebP

648
00:32:30,880 --> 00:32:34,619
其他檢視器也能當作 WebP 讀進去

649
00:32:34,619 --> 00:32:39,079
Huffman 編碼會出現兩次以上

650
00:32:39,079 --> 00:32:40,660
這點比較讓人困惑

651
00:32:40,660 --> 00:32:45,980
不過這邊搞定之後，剩下就照順序一個個實作下去就好

652
00:32:45,980 --> 00:32:50,359
把它實作完，其實離終點就不遠了

653
00:32:50,359 --> 00:32:55,019
這邊我們再回頭看一次整個編碼流程

654
00:32:55,019 --> 00:32:57,539
應該會比剛才更清楚一點

655
00:32:57,539 --> 00:33:01,319
必須的步驟只有這個紅色的 Huffman coding

656
00:33:01,319 --> 00:33:05,380
有這個再加上 header，基本上就能被當作 WebP 圖片來辨識

657
00:33:05,380 --> 00:33:08,900
就算不做這些綠色的步驟，只是要產生 WebP 圖片也沒問題

658
00:33:08,900 --> 00:33:11,640
綠色這些處理都是可選的

659
00:33:11,640 --> 00:33:14,859
目的是讓 Huffman 編碼更有效

660
00:33:14,859 --> 00:33:16,859
也就是所謂的前處理

661
00:33:16,859 --> 00:33:18,319
大概就是這樣

662
00:33:18,319 --> 00:33:21,200
接下來就一一看剩下那些綠色的處理

663
00:33:21,200 --> 00:33:24,000
首先是 Subtract Green

664
00:33:24,000 --> 00:33:27,779
以綠色為基準，把多餘的部分扣掉

665
00:33:27,779 --> 00:33:33,279
Huffman 編碼搞定之後

666
00:33:33,279 --> 00:33:35,799
建議下一步就做這個

667
00:33:35,799 --> 00:33:43,220
這個做法是在每個像素上，從紅和藍的成分裡減去綠

668
00:33:43,220 --> 00:33:47,299
降低色彩分量的相關性，讓壓縮更吃香的一種轉換

669
00:33:47,299 --> 00:33:50,400
它真的就只是相減，非常簡單

670
00:33:50,400 --> 00:33:52,700
做起來很容易

671
00:33:52,700 --> 00:33:55,480
就是從 Red 和 Blue 裡把 Green 減掉而已

672
00:33:55,480 --> 00:33:58,579
如果發生 underflow，就用 wrap-around 繞回來

673
00:33:58,579 --> 00:34:01,900
為什麼要減 Green 呢

674
00:34:01,900 --> 00:34:04,740
大多數圖片可以拆成「亮度」和「色度」來思考

675
00:34:04,740 --> 00:34:07,980
亮度的份量通常很大

676
00:34:07,980 --> 00:34:09,239
而色差通常比較小

677
00:34:09,239 --> 00:34:10,699
所以我們想把亮度那一塊削掉

678
00:34:10,699 --> 00:34:15,880
人眼對綠色最敏感、最容易感到亮度

679
00:34:15,880 --> 00:34:17,860
在一般的色彩空間裡

680
00:34:17,860 --> 00:34:20,320
綠色分量多半承擔了亮度的成分

681
00:34:20,320 --> 00:34:23,940
因此從紅和藍裡把綠扣掉

682
00:34:23,940 --> 00:34:26,159
共同的亮度部分會被抵銷

683
00:34:26,159 --> 00:34:28,019
只剩下色差

684
00:34:28,019 --> 00:34:31,539
而色差一般不會太大

685
00:34:31,539 --> 00:34:34,440
分布就會更集中

686
00:34:34,440 --> 00:34:36,300
於是更容易壓縮

687
00:34:36,300 --> 00:34:38,019
解碼則相反

688
00:34:38,019 --> 00:34:41,079
我們雖然在紅和藍扣掉了綠

689
00:34:41,079 --> 00:34:42,760
但綠本身是原封不動留著的

690
00:34:42,760 --> 00:34:45,960
解碼時把留下來的 Green 加回去就好

691
00:34:45,960 --> 00:34:47,559
很簡單對吧

692
00:34:47,559 --> 00:34:52,880
後面的流程也會讓人覺得這招設計得不錯

693
00:34:52,880 --> 00:34:57,659
因為綠是保留著的，直接拿來相加就行

694
00:34:57,659 --> 00:34:59,579
我自己覺得這點還挺有趣的

695
00:34:59,579 --> 00:35:02,940
我們實際來看一下效果

696
00:35:02,940 --> 00:35:07,960
這招對那種偏灰的圖特別有效

697
00:35:07,960 --> 00:35:10,840
因為灰基本上就是亮度占大宗

698
00:35:10,840 --> 00:35:13,340
如果是純灰階，做了 Subtract Green 之後

699
00:35:13,340 --> 00:35:14,340
這些分量會全部變成 0

700
00:35:14,340 --> 00:35:18,679
RGB 的數值大概會變成這樣

701
00:35:18,679 --> 00:35:19,860
實際上就是這個顏色

702
00:35:19,860 --> 00:35:24,119
把 R 和 B 都減去 Green 的話

703
00:35:24,119 --> 00:35:28,559
大多數數值會落在 -3 到 6 之間，變成非常非常小的值

704
00:35:28,559 --> 00:35:31,000
分布會緊緊地聚到 0 附近

705
00:35:31,000 --> 00:35:35,639
這樣一來 Huffman 的效果就會變得非常強

706
00:35:35,639 --> 00:35:39,320
這就是叫做 Subtract Green 的前處理

707
00:35:39,320 --> 00:35:42,320
也就是說它不一定對整張圖都有效，

708
00:35:42,320 --> 00:35:44,900
像是這種地面的顏色，

709
00:35:44,900 --> 00:35:46,519
或是陰天的天空這種顏色，

710
00:35:46,519 --> 00:35:50,059
一定會出現這種顏色連續的區域，

711
00:35:50,059 --> 00:35:54,420
在那類影像上這個前處理就特別有效。

712
00:35:54,420 --> 00:35:58,460
另外還會用到的是 LZ7。

713
00:35:58,460 --> 00:36:03,420
它是用距離和長度來表示重複的模式，藉此壓縮的機制。

714
00:36:03,420 --> 00:36:07,920
把這張圖用 LZ77 來編碼的話，

715
00:36:07,920 --> 00:36:14,079
在讀取的過程中，遇到連續的模式就會把它記錄下來，

716
00:36:14,079 --> 00:36:17,099
有點像在做快取。

717
00:36:17,099 --> 00:36:21,340
每讀一段就去比對看看是否和過去的模式一致，

718
00:36:21,340 --> 00:36:24,460
但要對每個像素都這樣做會非常花時間，

719
00:36:24,460 --> 00:36:27,400
基本上會每隔 3 個像素跳著讀。

720
00:36:27,400 --> 00:36:31,820
之所以是 3 個像素，是因為規格規定壓縮長度要在 3 以上，

721
00:36:31,820 --> 00:36:34,360
那樣讀會是效率最好的。

722
00:36:34,360 --> 00:36:36,900
如果又出現和某個模式相同的片段，

723
00:36:36,900 --> 00:36:39,820
就會去看這個模式能連續到什麼程度，

724
00:36:39,820 --> 00:36:41,039
能延伸就一直往前走，

725
00:36:41,039 --> 00:36:43,400
直到模式的連續性被打斷的地方，

726
00:36:43,400 --> 00:36:47,400
就會記錄成：從前面第 15 個像素開始，

727
00:36:47,400 --> 00:36:51,900
往後 5 個都是同樣的模式，這樣的資訊。

728
00:36:51,900 --> 00:36:58,539
也就是可以用像 153 這樣的另一種表達來替換。

729
00:36:58,539 --> 00:37:01,480
這就是所謂的 LZ7。

730
00:37:01,480 --> 00:37:05,139
這個與其說是為了 Huffman 符號化 的轉換，

731
00:37:05,139 --> 00:37:09,119
不如說是拿來處理 Huffman 符號化 壓不動的那類東西，

732
00:37:09,119 --> 00:37:12,000
Huffman 符號化是根據機率分佈來壓縮，

733
00:37:12,000 --> 00:37:14,440
但像重複、模式這種東西，

734
00:37:14,440 --> 00:37:17,079
在 Huffman 符號化 裡其實派不上用場，

735
00:37:17,079 --> 00:37:21,000
所以才需要用它來壓縮那些 Huffman 符號化 不擅長的重複或模式，

736
00:37:21,000 --> 00:37:23,440
算是一種互補性的手段。

737
00:37:23,440 --> 00:37:25,340
可以把它看成是這樣的一種壓縮方法。

738
00:37:25,340 --> 00:37:26,360
至於 LZ77，

739
00:37:26,360 --> 00:37:30,159
接下來是 Predict Transform，

740
00:37:30,159 --> 00:37:32,559
它是用左邊和上方的資訊來猜下一個顏色，

741
00:37:32,559 --> 00:37:37,340
利用左邊、左上、以及上方相鄰的像素，

742
00:37:37,340 --> 00:37:38,360
當前這個像素，

743
00:37:38,360 --> 00:37:40,360
大致上會落在相近的範圍，

744
00:37:40,360 --> 00:37:43,480
就去預測它可能會是什麼值，

745
00:37:43,480 --> 00:37:45,639
然後只記錄預測值和實際值之間的差，

746
00:37:45,639 --> 00:37:49,559
也就是取差並只把差值記下來的轉換。

747
00:37:49,559 --> 00:37:53,639
比方說現在已經把暗部的像素讀到這裡，

748
00:37:53,639 --> 00:37:54,619
而且都已經編碼了，

749
00:37:54,619 --> 00:37:57,039
接著要讀這個紅框的區域，

750
00:37:57,039 --> 00:37:58,579
準備把它編碼時，

751
00:37:58,579 --> 00:38:01,800
就會去估這個像素的值，

752
00:38:01,800 --> 00:38:04,639
根據相鄰的左、左上、以及上方的像素，

753
00:38:04,639 --> 00:38:05,500
來做預測。

754
00:38:05,500 --> 00:38:06,639
雖然說是預測，

755
00:38:06,639 --> 00:38:09,800
其實準不準並不是重點，

756
00:38:09,800 --> 00:38:14,119
重點是取差之後把值盡量變小，

757
00:38:14,119 --> 00:38:16,139
這樣分佈就會更集中，

758
00:38:16,139 --> 00:38:19,880
當然預測越接近越好，

759
00:38:19,880 --> 00:38:23,380
所以就用一些看起來合理的，

760
00:38:23,380 --> 00:38:24,719
也不完全只是經驗法則，

761
00:38:24,719 --> 00:38:27,000
但能讓結果接近的函式，

762
00:38:27,000 --> 00:38:29,039
在規格裡預先定了 14 種，

763
00:38:29,039 --> 00:38:30,480
會套用它們，

764
00:38:30,480 --> 00:38:33,139
然後挑出表現最好的那一個。

765
00:38:33,139 --> 00:38:34,760
說到底其實怎樣都行，

766
00:38:34,760 --> 00:38:37,000
用什麼值都可以，

767
00:38:37,000 --> 00:38:39,159
只要相減之後變小就行。

768
00:38:39,159 --> 00:38:41,420
當然這個函式是共享的，

769
00:38:41,420 --> 00:38:43,900
解碼端也會用同一個函式來，

770
00:38:43,900 --> 00:38:45,519
把它解回來。

771
00:38:45,519 --> 00:38:49,960
Cross-Color 會把顏色之間的混色拆開，

772
00:38:49,960 --> 00:38:52,300
減小紅色和藍色的波動。

773
00:38:52,300 --> 00:38:54,699
這是什麼意思呢？

774
00:38:54,699 --> 00:38:57,960
做法是先把圖稍微切成區塊，

775
00:38:57,960 --> 00:38:59,440
在那裡乘上一些係數，

776
00:38:59,440 --> 00:39:03,800
本質上還是從 R 和 B 再減掉 Green，

777
00:39:03,800 --> 00:39:06,579
但和 Subtract Green 不同的是，

778
00:39:06,579 --> 00:39:11,420
它更著重在把小幅的色彩抖動降下來。

779
00:39:11,420 --> 00:39:15,780
像草地、或日本人膚色那種，

780
00:39:15,780 --> 00:39:19,860
顏色有點細碎閃爍、互相摻在一起的，

781
00:39:19,860 --> 00:39:25,960
在這類影像上能把分布大幅收斂。

782
00:39:25,960 --> 00:39:28,760
就是那種顏色有點暈開的區域，

783
00:39:28,760 --> 00:39:30,860
對這些地方特別有效。

784
00:39:30,860 --> 00:39:33,480
另外 Color Index 呢，

785
00:39:33,480 --> 00:39:37,219
當影像使用的顏色不超過 256 種時，

786
00:39:37,219 --> 00:39:40,559
就替每個顏色編號，改用編號來寫。

787
00:39:40,559 --> 00:39:43,840
只要在 256 以下就能用，

788
00:39:43,840 --> 00:39:46,860
算是蠻殺手鐧的一種壓縮，

789
00:39:46,860 --> 00:39:48,719
因為把所有顏色都換成編號，

790
00:39:48,719 --> 00:39:50,480
原本寫顏色的那些地方，

791
00:39:50,480 --> 00:39:59,079
資訊量就會大幅縮小，達到壓縮效果。

792
00:39:59,079 --> 00:40:01,440
最後是 Color Cache，

793
00:40:01,440 --> 00:40:02,679
這個滿有趣，

794
00:40:02,679 --> 00:40:04,500
會把出現過的顏色先快取起來，

795
00:40:04,500 --> 00:40:06,920
之後再出現相同的顏色時，只留下快取的索引，

796
00:40:06,920 --> 00:40:09,300
做的事情其實就是一個本地快取，

797
00:40:09,300 --> 00:40:10,820
放在記憶體裡的快取，

798
00:40:10,820 --> 00:40:12,860
本地。

799
00:40:12,860 --> 00:40:14,980
把出現過的東西放進快取，

800
00:40:14,980 --> 00:40:17,480
下次如果剛好在快取裡有，

801
00:40:17,480 --> 00:40:18,820
如果只把那個快取的索引送出去的話

802
00:40:18,820 --> 00:40:20,559
會想說，這不就是本機快取嗎

803
00:40:20,559 --> 00:40:23,460
就算把本機快取的資訊送過去

804
00:40:23,460 --> 00:40:23,639
這個

805
00:40:23,639 --> 00:40:27,460
就算送給對方也不可能解碼吧

806
00:40:27,460 --> 00:40:28,079
會這樣想的啦

807
00:40:28,079 --> 00:40:30,980
其實解碼也能做一樣的事喔

808
00:40:30,980 --> 00:40:32,340
一邊做編碼，

809
00:40:32,340 --> 00:40:35,059
把編碼過的東西放進快取

810
00:40:35,059 --> 00:40:36,599
啊，是解碼啦

811
00:40:36,599 --> 00:40:39,280
一路解碼，把已解碼的東西放進快取

812
00:40:39,280 --> 00:40:41,179
這樣一來就編碼完成了，所以

813
00:40:41,179 --> 00:40:43,159
如果收到「這個是從快取來的喔」這樣的資訊

814
00:40:43,159 --> 00:40:45,920
它就在快取裡，所以可以直接從那裡取用

815
00:40:45,920 --> 00:40:48,019
我覺得這點超有趣

816
00:40:48,019 --> 00:40:51,559
當然，快取要怎麼做

817
00:40:51,559 --> 00:40:52,679
裡面也各自有些訣竅啦

818
00:40:52,679 --> 00:40:54,739
雖然是本機快取，

819
00:40:54,739 --> 00:40:57,039
但要按順序讀取這點是一樣的

820
00:40:57,039 --> 00:41:00,840
只靠快取的索引就能解碼這件事

821
00:41:00,840 --> 00:41:01,980
我覺得真的很有趣

822
00:41:01,980 --> 00:41:03,639
我覺得這個做得很不錯

823
00:41:03,639 --> 00:41:04,579
就是一種壓縮方式啦

824
00:41:04,579 --> 00:41:07,360
不過它很簡單，所以實作也很簡單

825
00:41:07,360 --> 00:41:13,219
總之，希望大家覺得這個總結還挺有意思的

826
00:41:13,219 --> 00:41:17,139
我簡單帶過說明了 FPE 的原理和機制

827
00:41:17,139 --> 00:41:19,780
不是那種很酷的 UI 程式碼

828
00:41:19,780 --> 00:41:22,880
可能不至於讓你馬上想動手試試看

829
00:41:22,880 --> 00:41:25,400
圖片的壓縮機制

830
00:41:25,400 --> 00:41:29,400
尤其是剛剛看到的無損壓縮，是很追求合理性的

831
00:41:29,400 --> 00:41:33,420
如果能讓你覺得這是一套很優美的機制，我會很開心

832
00:41:33,420 --> 00:41:37,059
資料壓縮的思維不只用在圖片上，

833
00:41:37,059 --> 00:41:38,780
對各種資料處理也很有幫助

834
00:41:38,780 --> 00:41:41,940
接觸一次、記住有各種不同手法之後，

835
00:41:41,940 --> 00:41:43,980
我想會是個很能拓展視野的領域

836
00:41:43,980 --> 00:41:46,619
作為下一步，

837
00:41:46,619 --> 00:41:48,880
把範例裡提供的編碼器

838
00:41:48,880 --> 00:41:50,800
稍微做點最佳化會不錯

839
00:41:50,800 --> 00:41:54,400
範例裡，編碼器在大多數情況

840
00:41:54,400 --> 00:41:55,780
都是固定成只有一種

841
00:41:55,780 --> 00:41:57,639
但其實編碼器呢，

842
00:41:57,639 --> 00:42:00,500
會依照圖片決定要套用什麼轉換，

843
00:42:00,500 --> 00:42:02,960
也會更換方式或調整參數，

844
00:42:02,960 --> 00:42:05,019
來讓檔案更小

845
00:42:05,019 --> 00:42:09,519
所以就做這些事，試著各種調整，

846
00:42:09,519 --> 00:42:11,159
量測結果、拿來比較，

847
00:42:11,159 --> 00:42:14,219
如果能讓大小變得更小之類的，應該也會有不少新發現，

848
00:42:14,219 --> 00:42:15,119
我想會蠻有趣的

849
00:42:15,119 --> 00:42:18,019
這樣建立假設、執行、再驗證

850
00:42:18,019 --> 00:42:20,179
是改善的王道作法

851
00:42:20,179 --> 00:42:23,000
好好走一遍這樣的循環

852
00:42:23,000 --> 00:42:24,880
應該會不錯

853
00:42:24,880 --> 00:42:29,039
如果覺得今天的內容哪怕一點點有趣，

854
00:42:29,039 --> 00:42:30,360
我就很開心

855
00:42:30,360 --> 00:42:31,400
非常感謝大家

856
00:42:35,019 --> 00:42:40,280
感謝您的發表

857
00:42:40,280 --> 00:42:43,800
那接下來進入 Q&A

858
00:42:43,800 --> 00:42:47,119
有評論或提問的，請舉手示意

859
00:42:47,119 --> 00:42:58,980
好，那 Q&A 就到這邊結束

860
00:42:58,980 --> 00:43:02,119
接著是 1 分鐘回饋時間

861
00:43:05,019 --> 00:43:12,280
1 分鐘回饋時間

862
00:43:12,280 --> 00:43:15,280
請掃描螢幕上的 QR code

863
00:43:15,280 --> 00:43:17,219
並送出你的回饋

