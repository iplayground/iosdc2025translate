#!/usr/bin/env python3
import sys
import os
import subprocess

# === è‡ªå‹•å®‰è£ç¼ºå°‘çš„å¥—ä»¶ ===
def ensure_package(package_name):
    try:
        __import__(package_name)
    except ImportError:
        print(f"ğŸ“¦ åµæ¸¬åˆ°æœªå®‰è£å¥—ä»¶ '{package_name}'ï¼Œæ­£åœ¨è‡ªå‹•å®‰è£ä¸­...")
        try:
            subprocess.check_call([
                sys.executable, "-m", "pip", "install",
                package_name, "--break-system-packages"
            ])
            print(f"âœ… å·²æˆåŠŸå®‰è£ {package_name}")
        except subprocess.CalledProcessError as e:
            print(f"âŒ å®‰è£ {package_name} å¤±æ•—ï¼š{e}")
            sys.exit(1)

# æª¢æŸ¥å¿…è¦å¥—ä»¶
ensure_package("srt")
ensure_package("openai")
ensure_package("python-dotenv")

import srt
from openai import OpenAI
from dotenv import load_dotenv

# === è¼‰å…¥ .env ===
load_dotenv()

# === æª¢æŸ¥åƒæ•¸ ===
if len(sys.argv) < 2:
    print("ç”¨æ³•ï¼špython translate_srt.py <input.srt>")
    sys.exit(1)

input_path = sys.argv[1]
if not os.path.exists(input_path):
    print(f"æ‰¾ä¸åˆ°æª”æ¡ˆ: {input_path}")
    sys.exit(1)

# === è‡ªå‹•è¨­å®šè¼¸å‡ºè·¯å¾‘ ===
base, ext = os.path.splitext(input_path)
output_path = f"{base}.zh.srt"

# === åˆå§‹åŒ– OpenAI ===
api_key = os.getenv("OPENAI_API_KEY")
if not api_key:
    print("âŒ æ‰¾ä¸åˆ° OPENAI_API_KEYï¼Œè«‹åœ¨ .env æª”ä¸­è¨­å®šæˆ– export ç’°å¢ƒè®Šæ•¸ã€‚")
    sys.exit(1)
client = OpenAI(api_key=api_key)

# === è®€å–å­—å¹• ===
with open(input_path, "r", encoding="utf-8") as f:
    subs = list(srt.parse(f.read()))

# === æ‰¹æ¬¡ç¿»è­¯è¨­å®š ===
batch_size = 100

for start in range(0, len(subs), batch_size):
    end = min(start + batch_size, len(subs))
    subs_batch = subs[start:end]
    print(f"æ­£åœ¨ç¿»è­¯ç¬¬ {start+1}ï½{end} è¡Œ...")

    if all(not s.content.strip() for s in subs_batch):
        continue

    batch_text = "\n\n".join(
        [f"{i+1}. {sub.content.strip()}" for i, sub in enumerate(subs_batch)]
    )

    prompt = f"""ä½ æ˜¯ä¸€å€‹å°ˆæ¥­çš„æ—¥ä¸­å­—å¹•ç¿»è­¯è€…ã€‚

ä»¥ä¸‹æ˜¯ä¸€æ®µæ—¥æœ¬iOSé–‹ç™¼ç ”è¨æœƒçš„é€å­—ç¨¿å­—å¹•ï¼ˆSRTæ ¼å¼ï¼‰ã€‚
è«‹å°‡å…¶ä¸­çš„æ—¥æ–‡å°è©ç¿»è­¯æˆè‡ªç„¶ã€æµæš¢çš„ç¹é«”ä¸­æ–‡ã€‚

ã€é‡è¦è¦å‰‡ã€‘
- ä¿ç•™æ¯ä¸€è¡Œçš„ç·¨è™Ÿèˆ‡æ™‚é–“è»¸æ ¼å¼ï¼ˆä¾‹å¦‚ â€œ1â€, â€œ00:00:00,000 --> 00:00:05,000â€ï¼‰ã€‚
- åªç¿»è­¯å°è©å…§å®¹ï¼Œä¸è¦ä¿®æ”¹æˆ–åˆªé™¤ä»»ä½•æ™‚é–“ç¢¼ã€‚
- ä¸è¦æ–°å¢æˆ–åˆä½µè¡Œæ•¸ã€‚
- ä¸è¦åŠ å…¥ä»»ä½•èªªæ˜ã€æ‹¬è™Ÿã€æ¨™è¨»æˆ–ç©ºè¡Œã€‚
- æŠ€è¡“ç”¨èªï¼ˆä¾‹å¦‚ Swift, UIKit, API, UIView, ã‚«ã‚¹ã‚¿ãƒ UI, Xcode, Appleï¼‰è«‹ä¿ç•™åŸæ–‡ã€‚
- è‹¥æœ‰æ—¥èªèªåŠ©è©æˆ–èªæ°£è©ï¼ˆä¾‹å¦‚ã€Œã§ã™ã­ã€ã€Œã‹ãªã€ã€Œã£ã¦ã„ã†ã€ï¼‰ï¼Œè«‹è‡ªç„¶è½‰åŒ–ç‚ºä¸­æ–‡èªæ°£ã€‚
- è«‹ç¢ºä¿ä¸­æ–‡å¥å­è‡ªç„¶ä¸”å£èªåŒ–ï¼Œä½†ä¸å¤±å°ˆæ¥­æ„Ÿã€‚
- åƒ…è¼¸å‡ºå®Œæ•´çš„ç¿»è­¯å¾Œ SRT å…§å®¹ï¼Œä¸è¦å¤šé¤˜æ–‡å­—ã€‚

ç¯„ä¾‹ï¼š
åŸæ–‡ï¼š
1
00:00:00,000 --> 00:00:03,000
ã‚«ã‚¹ã‚¿ãƒ UIã‚’ä½œã‚‹ã®ã¯å¤§å¤‰ã§ã™ã€‚

è¼¸å‡ºï¼š
1
00:00:00,000 --> 00:00:03,000
è£½ä½œè‡ªè¨‚UIæ˜¯ä»¶å¾ˆä¸å®¹æ˜“çš„äº‹ã€‚

ä»¥ä¸‹æ˜¯è¦ç¿»è­¯çš„å…§å®¹ï¼š
"""

    try:
        response = client.chat.completions.create(
            model="gpt-5",
            messages=[{"role": "user", "content": prompt + "\n\n" + batch_text}],
        )
        translated_text = response.choices[0].message.content.strip()
        translated_lines = [
            line.strip() for line in translated_text.splitlines() if line.strip()
        ]
        for sub, line in zip(subs_batch, translated_lines):
            sub.content = line
    except Exception as e:
        print(f"âš ï¸ ç¬¬ {start+1}ï½{end} è¡Œç¿»è­¯å¤±æ•—ï¼š{e}")
        continue

# === å¯«å‡ºçµæœ ===
with open(output_path, "w", encoding="utf-8") as f:
    f.write(srt.compose(subs))

print(f"\nâœ… ç¿»è­¯å®Œæˆï¼è¼¸å‡ºæª”æ¡ˆï¼š{output_path}")
